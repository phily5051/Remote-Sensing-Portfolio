[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Phil’s remote sensing learning diary",
    "section": "",
    "text": "Hello, I am Phil from South Korea. This is my learning diary for CASA0023 Remotely Sensing Cities and Environments.\nTo learn more about the module, visit https://andrewmaclachlan.github.io/CASA0023/00-course_info.html"
  },
  {
    "objectID": "week_1.html",
    "href": "week_1.html",
    "title": "1  Week 1",
    "section": "",
    "text": "Summary\n\n\nDefinition of Remote Sensing\n\nAccording to NASA, remote sensing refers to information obtained at a distance. These sensors are placed on satellites or aircrafts and they detect and document reflected or emitted energy.\n\nWhat kinds of energy?\n\nTO cut it short, the answer is Electromagnetic Radiation (EMR). This energy travels in different forms of waves through the atmosphere. While human eyes only detects visible light, the sensors can utilise the full range of the electromagnetic spectrum to collect data.\n\n\n\n\n\n\n\n\n\nElectromagnetic Spectrum (Source: NASA Science)\n\nSensor Types\n\nThere are two types of remote sensors: active and passive sensors.\n\nActive sensor:\n\nemits electromagnetic energy and receives the reflected energy\ncan observe areas under most conditions as most active sensors operate in the microwave band of the electromagnetic spectrum\nrequires power source - solar energy\naffected by space weather - solar flares\n\nPassive sensor:\n\nusually detects reflected energy\nused for measuring physical attributes, such as land/sea surface temperature and vegetation cover\nhas limitations in observing areas in the presence of dense cloud cover\n\n\n\n\n\n\n\n\n\n\n\nPassive and Active Sensors (Source: NASA)\n\nDoes EMR interact with other factors?\n\nYes, these radiations are often influenced by Earth’s surface and atmospheric conditions, which might distort the original information.\n\n\n\n\n\n\n\n\n\nEMR’s interaction with surface and atmosphere (Source: Daneshgar, 2015)\n\n4 Resolutions of Remote Sensing Data\n\n\nSpatial resolution: sizes of the raster cells\nSpectral resolution:\n\nValues for each wavelength across the electromagnetic spectrum creates a spectral signature\nEvery object has its own unique spectral signature, thus it can be used for identifying a specific object\nBut spectral resolution is often affected by atmospheric particles which absorb parts of the spectrum\n\n\n\n\n\n\n\n\n\n\n\nAtmospheric Electromagnetic Opacity (Source: GIS Geography)\n\nTemporal resolution: frequency of the recorded data\nRadiometric resolution: sensor’s ability to detect subtle differences in energy which determines the quality of images\n\n\nApplication\n\nIn the context of climate change, the ability to map tree types are important as they are closely linked to biodiversity. As mentioned earlier, each feature has different spectral signatures. Durgante et al. (2013) have discovered that spectral signature of tree species was better than DNA identification in distinguishing tree species. The researchers used ‘Fourier-Transform Near-Infrared (FT-NIR)’. It obtained the best results of 99.4% of correct specimen identification when using 36 spectral readings per specimen. This somehow opens a new, cost- and time-efficient avenue in mapping forest resources. Their research is meaningful in a sense that it enables us to identify types of forests in which forests are not easily accessible by humans or should be intact from human interferences.\n\n\n\n\n\n\n\n\n\nSpectral signatures of each tree (Source: Durgante et al., 2013)\nThe potential of spectral signature can also be found in the business sector. Yang, Lee, and Williamson (2012) suggested that spectral signatures could be employed to blueberry yield estimation system. The research team confirmed six-class blueberry classification - 233, 551, 554, 691, 699, 1373 nm - yielded the best results. This showed the potential of the spectral signature in developing fast and low cost blueberry detector. Furthermore, this research expands the use of spectral signatures from academia to industry, and suggests that the use of spectral signature can be boundless.\n\n\n\n\n\n\n\n\n\nDifferent absorbance rate depending on blueberry’s growth (Source: Yang and Williamson, 2012)\n\nPersonal Reflection\n\nAs a person who is interested in urban green spaces, the spectral resolution was an interesting concept. After understanding how it can be applied in both academia and industry, I wondered whether the health of green spaces in a city can also be measured with it. Furthermore, I was wondering whether there are any methods that improve the quality of data obtained from passive sensors as they cannot obtain a good quality data in the presence of bad weather. Under the circumstances where we have passive sensors, are there any techniques that could correct images?\n\nReferences\n\nNASA EarthData. (n.d.) Available at: <https://www.earthdata.nasa.gov/> (Accessed: 26.01.2023)\nGIS Geography. (2022) ‘Why the Atmospheric Window Matters in Earth Science’[Online]. Available at: <https://gisgeography.com/atmospheric-window/> (Accessed: 26.01.2023)\n\n\n\n\nDurgante, Flávia Machado, Niro Higuchi, Ana Almeida, and Alberto Vicentini. 2013. “Species Spectral Signature: Discriminating Closely Related Plant Species in the Amazon with Near-Infrared Leaf-Spectroscopy.” Forest Ecology and Management 291: 240–48. https://doi.org/https://doi.org/10.1016/j.foreco.2012.10.045.\n\n\nYang, Ce, Won Suk Lee, and Jeffrey G. Williamson. 2012. “Classification of Blueberry Fruit and Leaves Based on Spectral Signatures.” Biosystems Engineering 113 (4): 351–62. https://doi.org/https://doi.org/10.1016/j.biosystemseng.2012.09.009."
  },
  {
    "objectID": "week_2.html",
    "href": "week_2.html",
    "title": "2  Week 2",
    "section": "",
    "text": "https://phily5051.github.io/CASA0023_wk2_slides/#1"
  },
  {
    "objectID": "week_3.html",
    "href": "week_3.html",
    "title": "3  Week 3",
    "section": "",
    "text": "3.1 Summary\n\n\nCauses of Remote Sensing Data Distortion\n\nRemotely sensed images often require corrections to be available for analysis. The image distortions occur due to the following factors:\n\nView angle: depending on the angle of the sensor, the area of interest might look different.\n\n\n\n\n\n\n\n\n\n\nView angle (Source: Shen et al., 2021)\n\nTopography: the shape of terrain might cause some flaws in the image.\n\n\n\n\n\n\n\n\n\n\nThe impact of topography on remote sensing images (Source: Julia Lenhardt)\n\nEarth rotation: Earth’s spinning motion poses another difficulty. Straight lines of an image can appear to be unnaturally curved or deformed.\n\n\n\n\n\n\n\n\n\n\nEffect of Earth’s motion (Source: National Learning Network for Remote Sensing)\n\nWind, and so on.\n\n\nData Corrections\n\n4 types of data correction methods are available for distorted images. These are Geometric, Atmospheric, Orthorectification corrections!\nFirst, we can kick off with Geometric Correction!\n\nGeometric Correction\n\nGeometric errors are normally introduced by internal and external factors (attitude and altitude change). And Ground Control Points (GPS) can be used for correcting the errors! This means, basically, we are identifying so-called “known points” in both sensed image and a reference data and use them to build regression models! But we need each GCP, which are “image coordinate” and “map coordinate”.\n\n\n\n\n\n\n\n\n\nGPS points from a map and Landsat image (Source: GeoLearn)\n\nSolution:\n\nLinear Regression in a “Backward mapping” fashion can be an answer to this problem. Backward mapping is going from output image to input image. This method goes through one pixel at a time and for each position in output image to calculate where in the input image a pixel must come from.\nThe result can be verified by using RMSE. The lower the value is, the more accurate the result is, and the threshold RMSE value is 0.5. To reduce the RMSE, more GPS can be added as well.But when we do this, we have to re-sample the final raster data. There are several resample methods, such as Nearest Neighbour, Linear, Cubic and Cubic spline.\n\n\n\n\n\n\n\n\n\nGeometric Correction (Source: Abdul Basith)\n\n\n\n\n\n\n\n\n\nNearest Neighbour Resampling method (Source: AWF-WIKI)\n\nAtmospheric Correction\n\nAtmospheric correction removes scattering and absorption effects of the atmosphere to improve the image. Absorption and scattering makes an image somewhat blurry as they reduce contrast of image.\n\n\n\n\n\n\n\n\n\nExample of an image before and after atmospheric correction (Source: NASA)\n\nSolution: there are two kinds of approaches - relative and absolute.\n\nRelative atmospheric correction typically consists of two methods.\n- Dark Object Subtraction (DOS): searches each band for the darkest pixel value. The scattering is removed by subtracting this value from every pixel in the band.\n\n\n\n\n\n\n\n\n\nAn improved image after DOS (Source: Wang et al., 2019)\n- Pseudo-Invariant Features (PIFs): is grounded upon statistical invariance of artificial elements, which do not exhibit seasonal variation. The differences in PIFs reflectance between dates are assumed to be due to atmospheric conditions and are linearly related.\n\n\n\n\n\n\n\n\n\nAn improved image after employing PIFs (Source: Schott et al., 1988)\nRelative atmospheric correction convert digital brightness values into scaled surface reflectance by using atmospheric radiative transfer models.\n\n\n\n\n\n\n\n\n\nBefore and after atmospheric correction using radiative transfer method (Source: Advanced Remote Sensing)\n\nOrthorectification Correction\n\nThis method removes distortions by making the images looked right above (at nadir). This correction necessiates sensor geometry and an elevation model.\n\n\n\n\n\n\n\n\n\nAn example of orthorectification correction (Source: Esri Insider, 2016)\n\nData Join\n\nJoining remote sensed images are coined as “Mosaicking”. Using histogram matching algorithm, similar brightness values are given to two images that are overlapped, and then the feathering is conducted.\n\n\n\n\n\n\n\n\n\nSix raster datasets are joined into one image (Source: ArcMap)\n\nImage Enhancement\n\nMaterials reflect different amounts of energy in the same wavelengths. However, sensors have a fixed range of Digital Number (DN) values between 4 to 105. If we expand this range, we could enhance the visual appearance of images. There are several methods to do this, which include Minimum-Maximum, Percentage Linear and Standard Deviation, and Piecewise Linear Contrast Stretch.\n\nMinimum-Maximum: utilises the full range of available brightness values\n\n\n\n\n\n\n\n\n\n\nMinimum-Maximum Linear Stretch (Source: OneStopGIS)\n\nPercentage Linear and Standard Deviation Stretch: is similar to the Minimum-Maximum linear contrast stretch but this method uses a specified minimum and maximum values that situate between a certain percentage of pixels from the mean of the histogram.\n\n\n\n\n\n\n\n\n\n\nPercentage Linear Contrast Stretch (Source: OneStopGIS)\n\nPiecewise Linear Contrast Stretch: is used when the distribution of a histogram in an image is bi or trimodal (Jensen and Schill, n.d.).\n\n\n\n\n\n\n\n\n\n\nPiecewise Linear Contrast Stretch (Source: Tsai and Yeh, 2008)\n\n3.2 Application\n\nImage enhancement techniques not only enhance visual appearance but also allows for comparison between images retrieved from different years.\nHan-qiu (2011) has attempted to compare thermal images from different years with the same date in order to investigate urban heat island (UHI). The thermal infrared bands of different date were processed with several image enhancement technologies.\nTo detect change of the UHI between different dates, the two thermal imageries were normalised and scaled to reduce the impacts caused by seasonal variations or weather conditions. Then, the images were overlaid to show difference between images by subtracting correponding pixels.\nThis research demonstrates how we can employ image enhancement technologies to compare images from different years in a quantitative fashion.\nIn addition to image enhancement technologies covered in the lecture, Hu et al. (2020) demonstrated that Convolutional Neural Networks (CNN) can enhance visual appearance of image greatly. The authors carried out performing several different image enhancement technologies on low-quality image.\n\n\n\n\n\n\n\n\n\nResults of different image enhancement methods (Source: Hu et al., 2020)\nTheir findings suggest remote-sensing CNN (RSCNN) has proven to be the most efficient method in enhancing visualisation effects and allowing a better interpretation. RSCNN showed the superiority in terms of Structural Similarity Index (SSIM) and Peak Signal-to-Noise_Ratio (PSNR) over conventional techniques.\n\n\n\n\n\n\n\n\n\nSSIM and PSNR of different image enhancement methods (Source: Hu et al., 2020)\nThis research somehow offered potentials in combining two different fields of studies - CNN and remote sensing -, and suggested that adding complexity to imagery can help us more natural results with more realistic textures and vivid details.\n\n3.3 Reflection\n\nThis week’s content gave me an answer for the questions I had from the first week. Numerous data correction technologies improve the quality of image collected and allow for facilitating data to be ready for analysis.\nHowever, as there are a variety of correction methods, it seems necessary to understand what causes flaws in the remotely sensed images and how to employ an appropriate correction method to that specific datasets. In addition, I wonder whether there is a preference in a particular correction method over other correction methods, depending on the domain of study field or industry.\nLastly, as we went through numerous technologies which enable us to identify objects or areas in a better and higher resolution. However, in the context of built environment, there are many objects in cities that look similar to each other, and this might pose a difficulty in classifying them.\nIn Data Science module, I came across a deep learning model called YOLOv5, which detects objects in remotely sensed images. The model was trained on custom datasets. Once the training is done, the model can be applied to satellite imagery of different resolutions and identify objects.\n\n\n\n\n\n\n\n\n\nObjects indicated by a bounding box and its probability (Source: Google Earth Engine for OSINT)\nIf we create a customised dataset which contains specific information about some types of urban infrastructure, and feed these to train a model, we might be able to build a deep learning object detection model targeted at urban environment. Together with the data correction and image enhancement methods we learnt, I think the object detection model could enable us to classify some technically-challenging objects in an urban setting.\n\n3.4 References\n\nGoogle Earth Engine for OSINT. (n.d.) ‘Object Detection in Satellite Imagery’[Online]. Available at: https://oballinger.github.io/GEE_OSINT/object_detection.html (Acessed: 08.02.2023)\nJensen, J.H. and Schill, S.R. (n.d.) ‘Contrast Enhancement’[PDF]. Available at: http://knightlab.org/rscc/legacy/RSCC_Contrast_Enhancement.pdf (Accessed: 08.02.2023)\n\n\n\n\nHan-qiu, Chen. 2011. “An Image Processing Technique for the Study of Urban Heat Island Changes Using Different Seasonal Remote Sensing Data.” Remote Sensing Technology and Application 18: 129–33.\n\n\nHu, Linshu, Mengjiao Qin, Feng Zhang, Zhenhong Du, and Renyi Liu. 2020. “RSCNN: A CNN-Based Method to Enhance Low-Light Remote-Sensing Images.” Remote Sensing 13 (December): 62. https://doi.org/10.3390/rs13010062."
  },
  {
    "objectID": "week_4.html",
    "href": "week_4.html",
    "title": "4  Week 4",
    "section": "",
    "text": "Summary\n\nIn this diary, I am going to talk about the biggest city plan in South Korea and how a low-level city plan guideline is aligned with its upper-level plan. In particular, I will focus on the implementation of the plan regarding environment and whether there is any implementation that can be benefited from using remote sensing.\n\nBrief Information about 2030 Seoul Plan\n\n2030 Seoul Plan is the highest level city plan in Seoul, South Korea. Provided that Seoul is a capital city in South Korea, its city plan is often considered as significant and determinant as a government-led plan, in terms of its impacts on citizens of Seoul and the country. The plan covers a number of sectors which include housing, transport and environment. The city plan presents Seoul’s future vision and outlines the city’s development plan for the next 10 years.\nWith regards to environment, the plan specifies 3 Targets and 11 Strategies. The 3 targets are as follows:\n\nTarget 1: Ecological city with numerous urban parks\nTarget 2: Energy-efficient city\nTarget 3: Disaster-free city\n\nAmong the illustrated targets, Strategy 1-4 under Target 1 suggests a number of ways to deal with particulate matter, which is one of the biggest environmental issues in South Korea and highly related to citizen’s life. One of the mitigation actions to deal with the air pollutants identified by the Seoul government is creating urban forests on those areas which are specifically vulnerable to fine dust.\n\n\n\n\n\n\n\n\n\n2030 Seoul Plan (Source: Seoul Metropolitan Government)\n\nUrban Forest Guideline for PM Mitigation\n\nUrban Forest Guideline for PM Mitigation is a low-level city plan which entails types of activities that will be executed in line with the 2030 Seoul Plan. The guideline specified a number of technical rules to follow regarding types of trees to plant, which areas are targeted for urban forests implementation, and suitable distance between each tree stand and so on.\nFurthermore, the guideline categorised six types of urban forests that could mitigate the concentration of PM. These are street trees, urban parks, forests around the city, vegetations in schools and river, and green spaces within proximity to residential areas.\n\n\n\n\n\n\n\n\n\nDistance between trees in residential areas (Source: Seoul Metropolitan Government)\n\n3 Functional Urban Forest Types for PM Mitigation\n\nThe said urban forest types can be grouped into 3 types of urban forests in terms of their objective and functionality. These are PM blockage urban forests, PM mitigation urban forests and Wind corridor urban forests.\n\nPM blockage urban forests:\n\ndense urban forests with 1,800 trees per ha\nto block PM diffusion\n\nPM mitigation urban forests:\n\nbetween 800 and 1,000 trees per ha\nto enhance PM absorption by urban forests\n\nWind corridor urban forests:\n\n500 trees per ha\nto introduce clean air to city centre\nto enable the outflow of congregated PM within the city due to vehicles and household heating.\n\n\n\n\n\n\n\n\n\n\n\n3 Types of PM Mitigation Urban Forest Types (Source: Korea Forest Service)\n\nApplication\n\nRemote sensing can come into play a key role in identifying what PM mitigation urban forest types are most suitable to a particular site within a city, and quantifying the amounts of PM absorbed by urban forests.\nRemote sensing is an effective measure to map and monitor PM concentrations (Zhang et al. 2021). This indicates that areas with routinely high PM concentrations can be detected by satellite images. Thus, government officials could take data-informed decisions and select the most suitable PM mitigation urban forest types for each particular area.\n\n\n\n\n\n\n\n\n\nAverage PM2.5 concentration between 2001 and 2006 mapped by remote sensing (Source: Zhang et al.)\nIn addition, Gupta et al. (2006) found that remote sensing can capture the movement of air pollutants over a large area as satellite measurements are available globally. Their findings allude to us that remote sensing could enable us to understand how much PM have been absorbed by urban forests by measuring the size of PM mass between areas. The policymakers could draw on these quantified data as a basis for future policies.\n\n\n\n\n\n\n\n\n\nDocumentation of 1-year change of PM2.5 mass concentration in five study regions (Source: Gupta et al.)\n\nLink to UN SDG Goals\n\nAccording to United Nations 2030 Sustainable Development Goals (SDGs), the use of remote sensing could contribute to achieving 2 SDGs goals.\n\nSDG 3. Good Health and Well-Being\n\nPM causes various health problems, such as lung and heart diseases. The reduction in PM could improve citizen’s health and quality of life.\n\nSDG 11. Sustainable Cities and Communities\n\nCreating urban forests, as a measure to mitigate PM, could not only reduce aereal PM but also contribute to building a safe and resilient built environment from other natural hazards.\n\n\n\nReflection\n\nThis week’s contents were somewhat different from what we have learnt past few months. Understanding policy and how remote sensing could come into play its part in realising the policy’s objective was interesting. The contemplation upon how remote sensing can be applied at a particular context and a site broadened my understanding. Of course, I am aware that remote sensing is one of many solutions that could assist in achieving policy’s goals, and 1-size-fits-all approach is not sufficient to solve similar problems in different contexts. Thanks to this week’s lecture, however, I could say that I came to understand how we can apply our theoretical and technical knowledge about remote sensing to solve the real problems.\n\nReferences\n\nKorea Forest Service. (n.d.) https://english.forest.go.kr/kfsweb/kfs/subIdx/Index.do?mn=UENG (Accessed: 02.02.2022)\nSeoul Metropolitan Government. (n.d.) https://www.seoul.go.kr/main/index.jsp (Accessed: 02.02.2022)\nUnited Nations. (n.d.) https://sdgs.un.org/goals (Accessed: 02.02.2022)\n\n\n\n\nGupta, Pawan, Sundar A. Christopher, Jun Wang, Robert Gehrig, Yc Lee, and Naresh Kumar. 2006. “Satellite Remote Sensing of Particulate Matter and Air Quality Assessment over Global Cities.” Atmospheric Environment 40 (30): 5880–92. https://doi.org/https://doi.org/10.1016/j.atmosenv.2006.03.016.\n\n\nZhang, Ying, Zhengqiang Li, Kaixu Bai, Yuanyuan Wei, Yisong Xie, Yuanxun Zhang, Yang Ou, et al. 2021. “Satellite Remote Sensing of Atmospheric Particulate Matter Mass Concentration: Advances, Challenges, and Perspectives.” Fundamental Research 1 (3): 240–58. https://doi.org/https://doi.org/10.1016/j.fmre.2021.04.007."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Durgante, Flávia Machado, Niro Higuchi, Ana Almeida, and Alberto\nVicentini. 2013. “Species Spectral Signature: Discriminating\nClosely Related Plant Species in the Amazon with Near-Infrared\nLeaf-Spectroscopy.” Forest Ecology and Management 291:\n240–48. https://doi.org/https://doi.org/10.1016/j.foreco.2012.10.045.\n\n\nGupta, Pawan, Sundar A. Christopher, Jun Wang, Robert Gehrig, Yc Lee,\nand Naresh Kumar. 2006. “Satellite Remote Sensing of Particulate\nMatter and Air Quality Assessment over Global Cities.”\nAtmospheric Environment 40 (30): 5880–92. https://doi.org/https://doi.org/10.1016/j.atmosenv.2006.03.016.\n\n\nHan-qiu, Chen. 2011. “An Image Processing Technique for the Study\nof Urban Heat Island Changes Using Different Seasonal Remote Sensing\nData.” Remote Sensing Technology and Application 18:\n129–33.\n\n\nHu, Linshu, Mengjiao Qin, Feng Zhang, Zhenhong Du, and Renyi Liu. 2020.\n“RSCNN: A CNN-Based Method to Enhance Low-Light Remote-Sensing\nImages.” Remote Sensing 13 (December): 62. https://doi.org/10.3390/rs13010062.\n\n\nYang, Ce, Won Suk Lee, and Jeffrey G. Williamson. 2012.\n“Classification of Blueberry Fruit and Leaves Based on Spectral\nSignatures.” Biosystems Engineering 113 (4): 351–62.\nhttps://doi.org/https://doi.org/10.1016/j.biosystemseng.2012.09.009.\n\n\nZhang, Ying, Zhengqiang Li, Kaixu Bai, Yuanyuan Wei, Yisong Xie, Yuanxun\nZhang, Yang Ou, et al. 2021. “Satellite Remote Sensing of\nAtmospheric Particulate Matter Mass Concentration: Advances, Challenges,\nand Perspectives.” Fundamental Research 1 (3): 240–58.\nhttps://doi.org/https://doi.org/10.1016/j.fmre.2021.04.007."
  },
  {
    "objectID": "week_5.html",
    "href": "week_5.html",
    "title": "5  Week 5",
    "section": "",
    "text": "5.1 Summary\n\n\n5.1.1 What is Google Earth Engine (GEE)\n\nGoogle Earth Engine is a planetary-scale geo-spatial analysis platform. It enables users to keep track of changes and quantify differences on Earth’s surface.\n\n\n\n\n\n\n\n\n\nIllustration of GEE Mechanism (Source: Google Earth Engine)\n\n5.1.2 Pros & Cons of GEE\n\nThe advantages and disadvantages of GEE are as follows:\n\nPros:\n\nGEE stores various, rich and ready-to-use datasets within its server.\nCloud-based processing: quickly analyses big data\nUser-friendly interface: easy and free access\nEnormous potential to collaborate with state-of-the-art technologies (Deep learning and Machine Learning)\n\nCons:\n\nEasy access could mean the potential possibilities for inappropriate use by some criminals\nDependence on Google: concerns around data privacy and security\nLearning curve: coding with Javascript can be challenging\nLimited data types: profoundly limited to satellite imagery, which may not provide access to all the data types that people need\n\n\n\n\n\n\n\n\n\n\n\nGEE Data Catalog (Source: Google Earth Engine)\n\n5.1.3 Aggregating Pixels in GEE\n\nTo allow large computations, GEE provides users with various scale options to choose from. When an image is fed into GEE, many lower resolution versions of the image are pre-computed, and these are known as Image Pyramids.\n\n\n\n\n\n\n\n\n\nGEE Image Pyramids (Source: Google Earth Engine)\nThe lowest level of the image pyramid represents native resolution. The ingested image data are aggregated to a higher pyramid levels until it reaches 256 * 256 pixel tiles. At this aggregation process, GEE uses nearest neighbors by default Google Earth Engine. By default, the pyramid tiles are created by calculating mean values. This is called resampling.\n\n\n\n\n\n\n\n\n\nExample of resampling (Source: SpatialThoughts)\n\n5.1.4 Objects in GEE\n\nThere are 9 object classes in GEE. Each class has its own class-specific functions to load and manipulate data.\n\n\n\n\n\n\n\n\n\nEarth Engine Class Types (Source: Google Earth Engine)\n\n5.1.5 Applicable Processes in GEE\n\n\nReducing images by regions:\n\nBy region(s): It reduces all the pixels in the region(s) to a statistic of the pixel data in the region(s). We can take an image and generate statistics for it. The images of code and result below are adjusted from Andy’s Material. I used the Global Forest Change datasets to see the average reflectance for each band within Sierra Nevada, USA.\n\n\n\n\n\n\n\n\n\n\n\nCode for reducing images by region - Mean values of Tree loss & Tree cover\n\n\n\n\n\n\n\n\n\nResults of reducing images by region on GEE Code Editor - Mean values of Tree loss & Tree cover\n\nReducing images by neighbourhoods:\n\nBy neighbourhoods: The neighbourhoods of a pixel in an image can be used to reduce the image.\n\n\n\n\n\n\n\n\n\n\n\nReducing Images by neighbourhoods (Google Earth Engine)\n\n5.2 Application\n\nGoogle Earth Engine has been widely applied, ranging from forest and vegetation studies to medical fields such as malaria (Kumar and Mutanga 2018). The display of satellite imagery on GEE has enabled us to identify any change occurred during a certain period of time. However, I was wondering whether detecting changes in land cover is the only thing that GEE can offer. In this section, I will focus on how GEE can be applied in collaboration with Machine Learning technologies, and what are the benefits of considering technological fusion.\nGEE can be an effective way of monitoring and mapping land cover. Brovelli, Sun, and Yordanov (2020) mapped and monitored the rainforest change in Brazil from 2000 and 2019. The forest cover was mapped at a 5-year period by using a Machine Learning algorithm on GEE platform.\n\n\n\n\n\n\n\n\n\nWork Flow of the research (Source: Brovelli, Sun, and Yordanov (2020))\nThe Random Forest (RF) was used to classify past and present land cover - forest and non-forest. The whole process of building the model was conducted on GEE platform. 80% of the datasets were used for training the model, and the rest was withheld for testing the accuracy of the model. Then, the output classification results were validated through high-resolution satellite images.\n\n\n\n\n\n\n\n\n\nRF Classification results (Source: Brovelli, Sun, and Yordanov (2020))\n\n\n\n\n\n\n\n\n\nValidation samples for RF model (Source: Brovelli, Sun, and Yordanov (2020))\nTo estimate the future state of the forests, Artificial Neural Network (ANN) was used to simulate forest cover.\n\n\n\n\n\n\n\n\n\nANN simulation result between 2010 and 2014 (Source: Brovelli, Sun, and Yordanov (2020))\n\n\n\n\n\n\n\n\n\nANN simulation result between 2019 and 2028 (Source: Brovelli, Sun, and Yordanov (2020))\nThe above research was utilising GEE as a main platform to build a ML model. By building a model, it allowed us for predicting the future state of the forests. The research also elaborated how they tested the RF model’s performance. However, if there is an issue of over-fitting in a model, is there any way that we could deal with this issue?\nFurthermore, the authors did not explain how they validated the ANN model. While the simulation results could provide us to predict the future state of the forests, there was no dataset or method that tested the model’s performance which casts a doubt on the ANN model.\n\n5.3 Reflection\n\nThis week’s content was an introductory lecture for the GEE. As I have not heard of GEE before, the whole concept was somewhat very new and interesting for me.\nThe use of Javascript to write code looked similar to Python, but it was quite different in terms of defining variables. In particular, the fact that datasets are stored within GEE server was very convenient. Storing data always took up a lot of memory in my computer and sometimes it was hard to set up or remember a directory whenever I had to proceess data on R. The datasets on server saved so much space in my computer as well as the ready-made code to import the datasets was really easy.\nIn addition, spatial join and reducing images were much faster on GEE. With a few lines of code, I was able to get the results I wanted which would require lots of lines in other programming languages.\nLastly, after doing a research on the application of GEE, I noticed that most of datasets stored within the GEE server were mostly about environment-related datasets, and many of the on-going research were mainly focusing on identifying change in the environment. Thus, I was wondering whether there is any current research in the context of urban environment. The change in an urban setting might not be as distinctive as deforestation or change in temperature. However, cities are growing and urban infrastructures are always changing. This gives us enough reason to make use of GEE to better understand fast-changing cities. Therefore, in the next session, I would love to do more research about how GEE can be potentially utilised in the urban environment.\n\nReferences\n\nGoogle Earth Engine. (n.d.) https://earthengine.google.com/ (Accessed: 28.02.2023)\nSpatialThoughts. (2021) https://spatialthoughts.com/2021/05/13/aggregating-population-data-gee/ (Accessed: 28.02.2023)\n\n\n\n\nBrovelli, Maria Antonia, Yaru Sun, and Vasil Yordanov. 2020. “Monitoring Forest Change in the Amazon Using Multi-Temporal Remote Sensing Data and Machine Learning Classification on Google Earth Engine.” ISPRS International Journal of Geo-Information 9 (10). https://doi.org/10.3390/ijgi9100580.\n\n\nKumar, Lalit, and Onisimo Mutanga. 2018. “Google Earth Engine Applications Since Inception: Usage, Trends, and Potential.” Remote Sensing 10 (10). https://doi.org/10.3390/rs10101509."
  }
]