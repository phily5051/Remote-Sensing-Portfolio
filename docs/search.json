[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Phil’s remote sensing learning diary",
    "section": "",
    "text": "This is my learning diary for CASA0023 Remotely Sensing Cities and Environments. To learn more about the module, visit https://andrewmaclachlan.github.io/CASA0023/00-course_info.html\n\n\n\n\n\n\n\n\n\n\n\nName: Philyoung Jeong\nStudent ID: 21047736\nBio:\nHello, I am Phil from South Korea.\nI am studying a master’s degree in Urban Spatial Science at UCL Bartlett Centre for Advanced Spatial Analysis (CASA).\n\n\n\nMy background is in Forest Science. I could say I have been interested in nature for a long time. In particular, I am a huge fan of urban green spaces. The fact that urban green spaces are within proximity to our daily life sphere and urban biodiversity depends on them fascinates me.\nThat is why I am studying at CASA to better understand the built environment with the hope to model a sustainable green city.\nI would love to learn more about how to model green spaces and best distribute the limited areas of them within a city. I hope I could understand how to maximise what urban green spaces can offer us and improve inhabitants’ access to green spaces in their daily life."
  },
  {
    "objectID": "week_1.html",
    "href": "week_1.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1.1 Definition of Remote Sensing\n\nAccording to NASA (n.d.), remote sensing refers to information obtained at a distance. These sensors are placed on satellites or aircrafts and they detect and document reflected or emitted energy.\n\n1.1.2 What kinds of energy?\n\nTo cut it short, the answer is Electromagnetic Radiation (EMR). Electromagnetic waves are waves comprising of oscillations of electric and magnetic fields that oscillate at right angles to each other. They exist as a large range of frequencies, with gamma waves having the highest frequency and radio waves the lowest frequency. While human eyes only detects visible light, the sensors can utilise the full range of the electromagnetic spectrum to collect data.\n\n\n\n\n\nElectromagnetic Spectrum (Source: NASA Science)\n\n\n\n\n\n1.1.3 Sensor Types\n\nThere are two types of remote sensors: active and passive sensors.\n\n\n\n\n\n\n\nSensor Type\nDescription\n\n\n\n\nActive sensor\n\nEmits electromagnetic energy and receives the reflected energy\nCan observe areas under most conditions as most active sensors operate in the microwave band of the electromagnetic spectrum\nRequires power source energy - solar energy\nAffected by space weather - solar flares\n\n\n\nPassive sensor\n\nUsually detects reflected energy\nUsed for measuring physical attributes, such as land/sea surface temperature and vegetation cover\nHas limitations in observing areas in the presence of dense cloud cover\n\n\n\n\n\n\n\n\n\nPassive and Active Sensors (Source: NASA)\n\n\n\n\n\n1.1.4. Does EMR interact with other factors?\n\nYes, these radiations are often influenced by Earth’s surface and atmospheric conditions, which might distort the original information.\n\n\n\n\n\nEMR’s interaction with surface and atmosphere (Source: Daneshgar (2015))\n\n\n\n\n\n1.1.5 Four Resolutions of Remote Sensing Data\n\n\nSpatial:\n\nSizes of the raster cells\nThe smaller the measure is, the more detailed the image is\n\nSpectral:\n\nValues for each wavelength across the electromagnetic spectrum creates a spectral signature\nEvery object has its own unique spectral signature, thus it can be used for identifying a specific object\nBut spectral resolution is often affected by atmospheric particles which absorb parts of the spectrum\n\n\n\n\n\n\n\nAtmospheric Electromagnetic Opacity (Source: GIS Geography)\n\n\n\n\n\nTemporal:\n\nFrequency of the recorded data\nThere is typically a trade-off between how detailed an image is and how frequently it is updated in terms of pixels\n\nRadiometric:\n\nSensor’s ability to detect subtle differences in energy which determines the quality of images\n\n\n\n1.2 Application\n\nIn this section, we will have a look at two studies in which spectral signature are employed in both academia and business.\n\n1.2.1 Species Spectral Signature: DiscriminatingClosely Related Plant Species in the Amazon with Near-InfraredLeaf-Spectroscopy\n\n\nSummary: Durgante et al. (2013) explored the use of Fourier-Transform Near-Infrared (FT-NIR) Leaf Spectroscopy* as a tool for discriminating closely related tree species in Amazonian forests. The researchers collected 36 spectral readings from the adaxial and abaxial surfaces of dried leaves for 159 individuals representing 10 species. Each spectral reading consisted of 1557 FT-NIR absorbance values. From these spectral readings, the researchers extracted Species Spectral Signatures (SSS) using discriminant analysis techniques, which represent the unique spectral properties of each species. The study suggests that Species Spectral Signatures (SSS) from FT-NIR Leaf Spectroscopy provides better results than current DNA barcoding for plant identification in tropical forests, and represents a fast, low-cost sampling technique.\nFT-NIR* measures the interaction of near-infrared light with a plant leaf sample to analyze its chemical composition and physiological status.\nResult: The best results showed 99.4% correct specimen identification when using the average of all 36 spectral readings per specimen and stepwise selected variables.\nComment:\nThis study was meaningful in contributing to the field of biodiversity inventory in tropical countries. The use of high technology instruments and appropriate techniques for discriminating tree species is essential for better forest management and conservation.\nThe results of this study suggest that the Species Spectral Signatures (SSS) from FT-NIR Leaf Spectroscopy could be a powerful tool for plant identification, especially in areas where DNA barcoding is challenging due to the lack of reproductive structures.\nLimitation: It should be noted that further tests are required to assess the potential of FT-NIR spectroscopy for plant identification at broader geographical and phylogenetic scales.\n\n\n\n\n\n\nSpectral Signatures of Each Tree (Source: Durgante et al. (2013))\n\n\n\n\n\n1.2.2 Classification of blueberry fruit and leaves based on spectral signatures\n\n\nSummary: Yang, Lee, and Williamson (2012) investigated the use of blueberry spectral analysis to provide necessary wavelengths for the development of a multispectral imaging system for estimating blueberry yield. Samples of fruit and leaves from different stages of maturity were collected from two blueberry fields in Florida, USA, in 2010 and 2011. The researchers used 3 classification models and found that an Multi-Nomial Logistic regression (MNR) model was the most efficient. The study suggests that a blueberry fruit detector could be developed using multispectral imaging.\nPre-Processing: Spectral reflectance was measured, and normalised indices were used to develop classification models using classification tree, principal component analysis, and multinomial logistic regression.\nResult: The study found that an Multi-Nomial Logistic regression (MNR) model with six wavelengths performed the best for the 2011 dataset, with a prediction accuracy of 100% for leaf and mature fruit, 97.8% for young fruit, 97.9% for near-young fruit, and 94.6% for near-mature fruit.\nComment: It was surprising to see that spectral signature can be also applied to business sector. The use of spectral analysis for crop yield estimation has the potential to significantly impact agricultural productivity. The findings of this study demonstrate the potential of using multispectral imaging to accurately estimate blueberry yield. This technology can help farmers make data-informed decisions regarding their crop management practices, leading to increased yields and reduced costs.\nLimitation: There should be more research that explore the potential of multispectral imaging for yield estimation in other crops too.\n\n\n\n\n\n\nDifferent Absorbance Rate depending on blueberry’s growth (Source: Yang, Lee, and Williamson (2012))\n\n\n\n\nA bit of thought…..\nI was mind-blown when I found out that spectral signature is like DNA!! Initially, I thought the remote sensing imagery are just images taken from a far distance but it turned out that they contain a whole lot of information than they look. This fact sparked my curiosity. If each object has its own distinctive spectral signature, could we also use this for mining valuable resources buried somewhere on this planet that might save millions of life?!\nFurthermore, with spectral signature, could we develop a ML model that helps us detect vulnerable or endangered species in the nature? This could be more time-, cost-effective than previous methods that are being employed in the field.\n\n1.3 Reflection\n\nBefore taking this lecture, I did hear about the terminology “remote sensing”. But I have to admit that I was quite scared of it as it appealed to me so-called “elite-science”. Of course, we do see a lot of remote sensing imagery in our daily life but not many of us actually use the imagery to do work or study. In this regard, the introduction to remote sensing helped me feel more familiar with this domain of study field.\nThings I found interesting!!\n\nI, personally, found the spectral resolution very interesting. Its limitless usage - both in academia and business - made me wonder if it could be also used in the context of the urban environment. As a person who is interested in urban green spaces, I wondered whether the health of green spaces in a city can also be measured with the spectral resolution. For instance, ill trees could show different patterns compared to those of the healthy ones.\nFurthermore, I was wondering whether there are any methods that improve the quality of data obtained from passive sensors as they cannot obtain a good quality data in the presence of bad weather. Under the circumstances where we have passive sensors, are there any techniques that could correct images?\n\nAny considerations?\nWhile free access and publicly availability are the Earth Observation (EO) data’ real power, the EO data should be treated with caution. The analysis based on EO data can be misleading if it does not contain any context data, such as demographic and economic data. Therefore, it seems necessary that we fully understand the context when we do our analysis!!\nAny link to policy?\nApart from what I mentioned, there will be more opportunities that remote sensors can come into play in achieving policy goals. The terminology “remote sensing” is not yet appearing in policy documents, but the time will come. Who would not want to make use of freely available data and its numerous advantages??\n\nReferences\n\nNASA EarthData. (n.d.) https://www.earthdata.nasa.gov/ (Accessed: 26.01.2023)\nGIS Geography. (2022) ‘Why the Atmospheric Window Matters in Earth Science’[Online]. Available at: https://gisgeography.com/atmospheric-window/ (Accessed: 26.01.2023)\n\n\n\n\nDaneshgar, Saba. 2015. “Remote Sensing Observations for Monitoring Coastal Zones, Volturno River Mouth Case Study.” PhD thesis. https://doi.org/10.13140/RG.2.1.3806.9209.\n\n\nDurgante, Flávia Machado, Niro Higuchi, Ana Almeida, and Alberto Vicentini. 2013. “Species Spectral Signature: Discriminating Closely Related Plant Species in the Amazon with Near-Infrared Leaf-Spectroscopy.” Forest Ecology and Management 291: 240–48. https://doi.org/https://doi.org/10.1016/j.foreco.2012.10.045.\n\n\nYang, Ce, Won Suk Lee, and Jeffrey G. Williamson. 2012. “Classification of Blueberry Fruit and Leaves Based on Spectral Signatures.” Biosystems Engineering 113 (4): 351–62. https://doi.org/https://doi.org/10.1016/j.biosystemseng.2012.09.009."
  },
  {
    "objectID": "week_2.html",
    "href": "week_2.html",
    "title": "2  SAR Sensor",
    "section": "",
    "text": "This week’s learning diary is to investigate a remote sensor we are interested in, create a Xaringan presentation and host it on a learning diary. The presentation consists of a general overview of the sensor, its application with regard to forestry, urban environment and geology, and my personal reflection."
  },
  {
    "objectID": "week_3.html",
    "href": "week_3.html",
    "title": "3  Corrections",
    "section": "",
    "text": "3.1.1 Data Distortion\n\nRemotely sensed images often require corrections to be available for analysis. The image distortions occur due to the following factors:\n\nView angle: Depending on the angle of the sensor, the area of interest might look different.\n\n\n\n\n\n\nView angle (Source: Shen et al., 2021)\n\n\n\n\n\nTopography: The shape of terrain might cause some flaws in the image.\n\n\n\n\n\n\nImpact of Topography on Remote Sensing Images (Source: Julia Lenhardt)\n\n\n\n\n\nEarth rotation: Earth’s spinning motion poses another difficulty. Straight lines of an image can appear to be unnaturally curved or deformed.\n\n\n\n\n\n\nEffect of Earth’s motion (Source: National Learning Network for Remote Sensing)\n\n\n\n\n\n3.1.2 Data Corrections\n\nGeometric, Atmospheric and Orthorectification corrections can be applied to correct distorted images.\n\n(1) Geometric Correction\n\n\nCause: geometric error, introduced by internal and external factors (attitude and altitude change).\nSolution:\n\nGround Control Points (GCP): “known points” in both sensed image and a reference data\n\nBackward mapping (Linear model): process of using GCP to infer the characteristics of the corresponding remote sensing data by building or refining models\nModel verification: RMSE can be used - threshold 0.5\n\n\n\n\n\n\n\n\nGPS points from a map and Landsat image (Source: GeoLearn)\n\n\n\n\n\n\n\n\n\nGeometric Correction (Source: Abdul Basith)\n\n\n\n\n\n(2) Atmospheric Correction\n\n\nThis method removes scattering and absorption effects of the atmosphere to improve the image - absorption and scattering makes an image somewhat blurry as they reduce contrast of image.\n\n\n\n\n\n\nExample of an image before and after atmospheric correction (Source: NASA)\n\n\n\n\n\nSolution: Relative and Absolute approaches\n\nRelative atmospheric correction\n\nDark Object Subtraction (DOS):\n\nSearches each band for the darkest pixel value\nThe scattering is removed by subtracting this value from every pixel in the band.\n\n\n\n\n\n\n\nAn improved image after DOS (Source: Wang et al., 2019)\n\n\n\n\n\nPseudo-Invariant Features (PIFs):\n\nGrounded upon statistical invariance of artificial elements, which do not exhibit seasonal variation\nThe differences in PIFs reflectance between dates are assumed to be due to atmospheric conditions and are linearly related.\n\n\n\n\n\n\n\nAn improved image after employing PIFs (Source: Schott et al., 1988)\n\n\n\n\nAbsolute atmospheric correction converts digital brightness values into scaled surface reflectance by using atmospheric radiative transfer models.\n\n\n\n\n\nBefore and after atmospheric correction using radiative transfer method (Source: Advanced Remote Sensing)\n\n\n\n\n\n(3) Orthorectification Correction\n\n\nThis method removes distortions by making the images looked right above (at nadir). This correction necessitates sensor geometry and an elevation model.\n\n\n\n\n\n\nAn example of orthorectification correction (Source: Esri Insider, 2016)\n\n\n\n\n\n3.1.3 Data Join\n\nJoining remote sensed images are coined as “Mosaicking”. Using histogram matching algorithm, similar brightness values are given to two images that are overlapped, and then the feathering is conducted.\n\n\n\n\n\nSix raster datasets are joined into one image (Source: ArcMap)\n\n\n\n\n\n3.1.4 Image Enhancement\n\n\nMaterials reflect different amounts of energy in the same wavelengths. However, sensors have a fixed range of Digital Number (DN) values between 4 to 105.\nThe following methods could enhance the visual appearance of images by expanding this range.\nMinimum-Maximum: Utilises the full range of available brightness values\n\n\n\n\n\n\nMinimum-Maximum Linear Stretch (Source: OneStopGIS)\n\n\n\n\n\nPercentage Linear and Standard Deviation Stretch:\n\nSimilar to the Minimum-Maximum linear contrast stretch\nIt uses a specified minimum and maximum values\n\n\n\n\n\n\n\nPercentage Linear Contrast Stretch (Source: OneStopGIS)\n\n\n\n\n\nPiecewise Linear Contrast Stretch: Used when the distribution of a histogram in an image is bi or trimodal (Jensen and Schill, n.d.).\n\n\n\n\n\n\nPiecewise Linear Contrast Stretch (Source: Tsai and Yeh, 2008)\n\n\n\n\n\n3.2 Application\n\nImage enhancement techniques not only enhance visual appearance but also allow for comparison between images retrieved from different years. In this part, I did research about how else image enhancement technology can be utilised apart from improving an image quality, and a novel way of using a deep learning model to enhance the quality of image.\n\n3.2.1 RSCNN: A CNN-Based Method to Enhance Low-Light Remote-Sensing Images\n\n\nSummary: Hu et al. (2020) proposes a new neural network architecture called Remote-Sensing CNN (RSCNN) for enhancing low-light remote-sensing images. RSCNN uses CNNs, including LLCNN and SRCNN, and an upsampling operator to learn multi-scaled features. Due to the lack of labeled training data in remote-sensing image datasets, the study uses real natural image patches to train initially and fine-tunes with simulated remote-sensing image pairs. The study’s experiments show that RSCNN outperforms conventional techniques in terms of SSIM and PSNR and has qualitative advantages in denoising and maintaining color and texture authenticity.\nData:\n\nDeepISP: It consists of 110 pairs of normal and low-light exposure images\nUCMerced: This dataset contains 21 types of land use images\n\nResult: The results of RSCNN are compared with traditional low-light enhancement algorithms, and the results show that RSCNN has better quantitative analysis indicators and can be applied to low-light remote-sensing image enhancement tasks.\nComment:\nIn addition to image enhancement technologies covered in the lecture, this study demonstrates that Convolutional Neural Networks (CNN) can enhance visual appearance of image greatly. The study’s proposed RSCNN architecture is an exciting development in image enhancement technology, particularly for remote-sensing images.\nThe use of real natural image patches for initial training and fine-tuning with simulated remote-sensing images is a smart approach to addressing the lack of labeled training data. The experiments’ qualitative and quantitative results demonstrate RSCNN’s superiority over conventional techniques, which is encouraging.\nOverall, this research offered potentials in combining two different fields of studies - CNN and remote sensing -, and suggested that adding complexity to imagery can help us more natural results with more realistic textures and vivid details.\nLimitation: The proposed method is evaluated on a limited set of datasets, and the generalization of the method to other remote-sensing datasets needs to be further investigated.\n\n\n\n\n\n\nResults of different image enhancement methods (Source: Hu et al., 2020)\n\n\n\n\n\n\n\n\n\nSSIM and PSNR of different image enhancement methods (Source: Hu et al., 2020)\n\n\n\n\n\n3.3 Reflection\n\nThis week’s content gave me an answer for the questions I had from the first week. Numerous data correction technologies improve the quality of image collected and allow for facilitating data to be ready for analysis.\nTakeaway message\n\nAs there are a variety of correction methods, it seems necessary to understand what causes flaws in the remotely sensed images and how to employ an appropriate correction method to that specific datasets.\n\nA bit of thought…..\n\nAny preference in correction method?\n\nI wonder whether there is a preference in a particular correction method over other correction methods, depending on the domain of study field or industry.\n\nObject-detection model in urban environment?!\n\nIn the context of built environment, there are many objects in cities that look similar to each other, and this might pose a difficulty in classifying them. In Data Science module, I came across a deep learning model called YOLOv5, which detects objects in remotely sensed images. The model was trained on custom datasets. Once the training is done, the model can be applied to satellite imagery of different resolutions and identify objects.\nIf we create a customised dataset which contains specific information about some types of urban infrastructure, and feed these to train a model, we might be able to build a deep learning object detection model targeted at urban environment.\nTogether with the data correction and image enhancement methods we learnt, I think the object detection model could enable us to classify some technically-challenging objects in an urban setting.\n\n\n\n\n\n\n\nObjects indicated by a bounding box and its probability (Source: Google Earth Engine for OSINT)\n\n\n\n\n\nReferences\n\nGoogle Earth Engine for OSINT. (n.d.) ‘Object Detection in Satellite Imagery’[Online]. Available at: https://oballinger.github.io/GEE_OSINT/object_detection.html (Acessed: 08.02.2023)\nJensen, J.H. and Schill, S.R. (n.d.) ‘Contrast Enhancement’[PDF]. Available at: http://knightlab.org/rscc/legacy/RSCC_Contrast_Enhancement.pdf (Accessed: 08.02.2023)\n\n\n\n\nHu, Linshu, Mengjiao Qin, Feng Zhang, Zhenhong Du, and Renyi Liu. 2020. “RSCNN: A CNN-Based Method to Enhance Low-Light Remote-Sensing Images.” Remote Sensing 13 (December): 62. https://doi.org/10.3390/rs13010062."
  },
  {
    "objectID": "week_4.html",
    "href": "week_4.html",
    "title": "4  Policy",
    "section": "",
    "text": "This week covers the way we can use remote sensing to assist in implementing data-driven local-, country-, regional-level policies, while in compliance to global agendas. As a case study, we will look into Seoul’s city plan - the biggest city plan in South Korea -, with special focus on the PM-related policies.\n\n4.1 Summary\n\n\n4.1.1 Context\n\n\n\n\n\n\nPoor Air Quality in Seoul in 2016, image taken from an aircraft (Source: NASA)\n\n\n\n\nAccording to NASA, Seoul, a capital city in South Korea, has some of the worst air pollution levels globally. Between 2009 and 2013, the average concentration of PM10 in Seoul was higher than that in many other major cities, including Los Angeles, Tokyo, Paris, and London. This severe pollution has caused health and environmental issues. To breathe cleaner air, people in Korea purchase masks and air purifiers, and the country struggles to reduce the PM levels.\n\nConsequences:\n\nHealth effects:\n\nHigher mortality - PM is attributable to the death of 165 Korean citizens\nAir pollution-related diseases - cancer, heart disease, pneumonia and low birth weight\n\nSocio-economic effects:\n\nEconomic damage of $ 9 billion a year, due to the decrease in economic activities\nImpact on a number of outdoor sports\n\n\n\n\n4.1.2 International Framework\n\nSustainable Development Goals (SDG)\n\n\n\n\n\nUnited Nation SDG (Source: United Nations)\n\n\n\n\nThe Sustainable Development Goals are a set of 17 interconnected aims adopted by all UN member states in 2015. The SDGs provide a common plan for achieving sustainable development by 2030, focusing on ending poverty, promoting peace and prosperity and all. The SDGs are an urgent call for action to create a better future for all people and the planet.\nSDGs regarding PM:\nUN SDG 03: Ensure healthy lives and promote well-being for all at all ages\n\nTarget 3.9: By 2030, substantially reduce the number of deaths and illnesses from hazardous chemicals and air, water and soil pollution and contamination\nIndicator 3.9.1: Mortality rate attributed to household and ambient air pollution\n\nUN SDG 11: Make cities and human settlements inclusive, safe, resilient and sustainable\n\nTarget 11.6: By 2030, reduce the adverse per capita environmental impact of cities, including by paying special attention to air quality and municipal and other waste management.\nIndicator 11.6.2: Annual mean levels of fine particulate matter (e.g. PM2.5 and PM10) in cities (population weighted)\n\n\n4.1.3 Metropolitan-level Framework\n\n\nGeneral Information about Seoul Plan\n\n2030 Seoul Plan is the highest-level city plan in Seoul, South Korea. Provided that Seoul is a capital city in South Korea, its city plan is often considered as significant and determinant as a government-led plan, in terms of its impacts on citizens of Seoul and the country. The plan has 5 focal points which include well-being ,employment, culture, environment and housing/transport, and it presents Seoul’s future vision and outlines the city’s development plan for the next 10 years.\nPolicy relevant to PM:\nFocal Point 4: A city where life thrives/breathes\n\nTarget 1: Urban park-led ecological city\n\nStrategy 1.3: Conservation, restoration, and enhancement of urban natural ecosystems for public benefits\n\nGuideline 1.3.4: Enhancement of public benefits of urban forests\n\nWide implementation of urban forests within the city\n\n\nStrategy 1.4: Qualitative improvement and optimisation of urban living environment\n\nGuideline 1.4.1: Reduction in Particulate Matter (PM) and smog\n\nPromote environmentally-friendly cars such as electric and hybrid vehicles in the transportation sector\nModify road facilities to prevent the dispersion of PM\nExpand distribution of eco-friendly home boilers and dust-absorbing cleaning vehicles to roads\n\n\n\n\nAs we can see, Strategy 1.3 and Strategy 1.4 suggest a number of ways to reduce PM, which is one of the biggest environmental issues in South Korea and highly related to citizen’s life. One of the mitigation actions to deal with the air pollutants identified by the Seoul government is creating urban forests on those areas which are specifically vulnerable to fine dust.\n\n4.1.4 Detailed Guideline for PM Mitigation Urban Forests\n\nUrban Forest Guideline for PM Mitigation entails types of PM reduction activities that will be executed in line with the 2030 Seoul Plan. Following the guideline, a number of technical rules are specified. These rules include types of trees to plant, which areas are targeted for urban forests implementation, and suitable distance between each tree stand and so on.\nFurthermore, under the guideline six types of urban forests are categorised so they could reduce the concentration of PM. These are street trees, urban parks, forests around the city, vegetations in schools and river, and green spaces within proximity to residential areas.\n\n\n\n\n\nDistance between trees in residential areas (Source: Seoul Metropolitan Government)\n\n\n\n\n\n4.1.5 Three Types of PM Mitigation Urban Forest Types\n\nThe urban forest types can be grouped into 3 types of urban forests in terms of their objective and functionality. These are PM blockage urban forests, PM mitigation urban forests and Wind corridor urban forests.\n\nPM blockage urban forests:\n\nDense urban forests with 1,800 trees per ha\nBlock PM diffusion\n\nPM mitigation urban forests:\n\nBetween 800 and 1,000 trees per ha\nEnhance PM absorption by urban forests\n\nWind corridor urban forests:\n\n500 trees per ha\nIntroduce clean air to city centre\nEnable the outflow of congregated PM within the city due to vehicles and household heating.\n\n\n\n\n\n\n\n3 Types of PM Mitigation Urban Forest Types (Edited, Original image by Korea Forest Service)\n\n\n\n\n\n4.2 Application\n\nIn this section, I would like to introduce two articles that might help find the most optimal location of PM mitigation urban forests, and some factors that need to be considered in monitoring PM2.5.\n\n4.2.1 Satellite remote sensing of atmospheric particulate matter mass concentration: Advances, challenges, and perspectives\n\n\nSummary: Remote sensing is an effective measure to map and monitor PM concentrations (Zhang et al. 2021). The study provides a comprehensive overview of the progress made and challenges faced in measuring the concentration of atmospheric particulate matter (PM) using satellite observations over the last 20 years. It examines the development of satellite platforms, sensors, algorithms, and datasets, as well as various methods for estimating PM mass concentrations, which are classified into four categories: univariate regression, chemical transport models (CTM), multivariate regression, and empirical physical approaches. The authors suggest a hybrid method that combines the benefits of these methods to generate accurate and continuous PM concentration maps.\nComment:\nI think this study well-emphasised the significance of using satellite-based PM concentration mapping practices for monitoring air quality and managing environmental health. This is crucial in understanding the sources and distribution of PM and identifying effective strategies for mitigation, given the increasing concerns over air pollution and its impacts on human health.\nIn particular, more studies like this could enable government officials to take data-informed decisions and select the most suitable PM mitigation urban forest types for each particular area. The hybrid method proposed in the study shows promise in addressing the challenges faced in PM mapping practices and improving the accuracy and reliability of PM concentration estimates.\nLimitation: It seems necessary to validate and improve this approach and assess its suitability in different regions and weather conditions.\n\n\n\n\n\n\nAverage PM2.5 concentration between 2001 and 2006 mapped by remote sensing (Source: Zhang et al. (2021))\n\n\n\n\n\n4.2.2 Satellite remote sensing of particulate matter and air quality assessment over global cities\n\n\nSummary: Gupta et al. (2006) attempts to evaluate the use of aerosol optical thickness (AOT) retrievals from the MODerate resolution Imaging Spectro-radiometer (MODIS) along with ground measurements of PM2.5 mass concentration to assess particulate matter air quality over 26 locations in different global urban areas. The study finds that satellite-derived AOT is a good surrogate for monitoring PM air quality over the earth, but the PM2.5-AOT relationship strongly depends on several factors, including aerosol concentrations, ambient relative humidity, fractional cloud cover, and height of the mixing layer.\nResult: The study shows that there is an excellent correlation between satellite and ground-based values, with a linear correlation coefficient of 0.96. It also suggests that the effects of wind speed, cloud cover, and mixing height on particulate matter air quality should also be considered to further apply satellite data for air quality research.\nComment: I would say this study’s findings are meaningful with regards to the AOT’s potential as a substitute for ground-based PM measurements in areas with limited or unavailable ground data. However, the correlation between PM2.5 and AOT is heavily influenced by several factors such as aerosol concentration, relative humidity, cloud cover, and mixing layer height, which must be taken into account. I think the analysis can be benefited from including additional meteorological and ancillary datasets, and remote sensing sensors that provide vertical aerosol distribution. The study provides valuable insights into the use of satellite data for air quality research, but it is necessary to consider the limitations and uncertainties associated with this approach in future studies.\n\n\n\n\n\n\nDocumentation of 1-year change of PM2.5 mass concentration in five study regions (Source: Gupta et al. (2006))\n\n\n\n\nA bit of thought…..\nThe application of remote sensing to locating the optimal location of PM mitigation urban forests could be linked to the following SDGs:\n\nUN SDG 03: Good Health and Well-Being\n\nPM causes various health problems, such as lung and heart diseases. The reduction in PM could improve citizen’s health and quality of life.\n\nUN SDG 11: Sustainable Cities and Communities\n\nCreating urban forests, as a measure to mitigate PM, could not only reduce aereal PM but also contribute to building a safe and resilient built environment from other natural hazards.\n\n\n\nReflection\n\nThis week’s contents were very different from what we have learnt in the past few months. Understanding policy and how remote sensing could come into play its part in realising the policy’s objective was interesting. The contemplation upon how remote sensing can be applied at a particular context and a site broadened my understanding of where remote sensing can be applied in the policy implementation.\nOf course, I am aware that remote sensing is one of many solutions that could assist in achieving policy’s goals, and 1-size-fits-all approach is not sufficient to solve similar problems in different contexts. Thanks to this week’s lecture, however, I could say that I came to understand how we can apply our theoretical and technical knowledge about remote sensing to solve the real problems.\nAny considerations?\nIn the future, I would like to look into environmental policies of developing countries as their contexts might be very different from the example we covered here. For developing countries, economic growth seems to be placed before environment. Consequently, some countries might not have sufficient guidelines to be in line with global agendas, and in worst cases they might not have policies.\nOur role in this challenge?\nTherefore, it would be very interesting to explore how we can help bridge this gap between country-level policies and global policies by assisting in framing their policies and raising public awareness.\n\nReferences\n\nKorea Forest Service. (n.d.) https://english.forest.go.kr/kfsweb/kfs/subIdx/Index.do?mn=UENG (Accessed: 02.02.2022)\nSeoul Metropolitan Government. (n.d.) https://www.seoul.go.kr/main/index.jsp (Accessed: 02.02.2022)\nUnited Nations. (n.d.) https://sdgs.un.org/goals (Accessed: 02.02.2022)\n\n\n\n\nGupta, Pawan, Sundar A. Christopher, Jun Wang, Robert Gehrig, Yc Lee, and Naresh Kumar. 2006. “Satellite Remote Sensing of Particulate Matter and Air Quality Assessment over Global Cities.” Atmospheric Environment 40 (30): 5880–92. https://doi.org/https://doi.org/10.1016/j.atmosenv.2006.03.016.\n\n\nZhang, Ying, Zhengqiang Li, Kaixu Bai, Yuanyuan Wei, Yisong Xie, Yuanxun Zhang, Yang Ou, et al. 2021. “Satellite Remote Sensing of Atmospheric Particulate Matter Mass Concentration: Advances, Challenges, and Perspectives.” Fundamental Research 1 (3): 240–58. https://doi.org/https://doi.org/10.1016/j.fmre.2021.04.007."
  },
  {
    "objectID": "week_5.html",
    "href": "week_5.html",
    "title": "5  Introduction to Google Earth Engine",
    "section": "",
    "text": "5.1.1 What is Google Earth Engine (GEE)\n\nGoogle Earth Engine is a planetary-scale geo-spatial analysis platform. It enables users to keep track of changes and quantify differences on Earth’s surface.\n\n\n\n\n\nIllustration of GEE Mechanism (Source: Google Earth Engine)\n\n\n\n\n\n5.1.2 Pros & Cons of GEE\n\nThe advantages and disadvantages of GEE are as follows:\n\nPros:\n\nGEE stores various, rich and ready-to-use datasets within its server\nCloud-based processing: quickly analyses big data\nUser-friendly interface: easy and free access\nEnormous potential to collaborate with state-of-the-art technologies (Deep learning and Machine Learning)\n\nCons:\n\nEasy access could mean the potential possibilities for inappropriate use by some criminals\nDependence on Google: concerns around data privacy and security\nLearning curve: coding with Javascript can be challenging\nLimited data types: profoundly limited to satellite imagery, which may not provide access to all the data types that people need\n\n\n\n5.1.3 Aggregating Pixels in GEE\n\nTo allow large computations, GEE provides users with various scale options to choose from. When an image is fed into GEE, many lower resolution versions of the image are pre-computed, and these are known as Image Pyramids.\n\n\n\n\n\nGEE Image Pyramids (Source: Google Earth Engine)\n\n\n\n\nThe lowest level of the image pyramid represents native resolution. The ingested image data are aggregated to a higher pyramid levels until it reaches 256 * 256 pixel tiles. At this aggregation process, GEE uses nearest neighbors by default Google Earth Engine. By default, the pyramid tiles are created by calculating mean values. This is called resampling.\n\n\n\n\n\nExample of Resampling (Source: SpatialThoughts)\n\n\n\n\n\n5.1.4 Objects in GEE\n\nThere are 9 object classes in GEE. Each class has its own class-specific functions to load and manipulate data.\n\n\n\n\n\nEarth Engine Class Types (Source: Google Earth Engine)\n\n\n\n\n\n5.1.5 Applicable Processes in GEE\n\n\nReducing images by regions:\n\nBy region(s): It reduces all the pixels in the region(s) to a statistic of the pixel data in the region(s). We can take an image and generate statistics for it.\n\n\nNote. The images of code and result below are adjusted from the lecture and practical. Here, I used the Global Forest Change datasets to see the average reflectance for each band within Sierra Nevada, USA.\n\n\n\n\n\nCode for reducing images by region - Mean values of Tree loss & Tree cover\n\n\n\n\n\n\n\n\n\nResults of reducing images by region on GEE Code Editor - Mean values of Tree loss & Tree cover\n\n\n\n\n\nReducing images by neighbourhoods:\n\nBy neighbourhoods: The neighbourhoods of a pixel in an image can be used to reduce the image.\n\n\n\n\n\n\n\nReducing Images by neighbourhoods (Source: Google Earth Engine)\n\n\n\n\n\n5.2 Application\n\nGoogle Earth Engine has been widely applied, ranging from forest and vegetation studies to medical fields such as malaria (Kumar and Mutanga 2018). The display of satellite imagery on GEE has enabled us to identify any change occurred during a certain period of time. However, I was wondering whether detecting changes in land cover is the only thing that GEE can offer.\nIn this section, I will focus on how GEE can be applied in collaboration with Machine Learning technologies, and what are the benefits of considering technological fusion.\n\n5.2.1 Monitoring Forest Change in the Amazon Using Multi-Temporal Remote Sensing Data and Machine Learning Classification on Google Earth Engine\n\n\nSummary: Brovelli, Sun, and Yordanov (2020) aimed to map and monitor forest changes from 2000 to 2019 in a rainforest region in Pará state, Brazil, using satellite imagery and machine learning classification on Google Earth Engine. The results were validated through high-resolution image interpretation and showed a peak in deforestation rates from 2000 to 2006, followed by a decrease and stabilization until 2015, and a slight increase until 2019. Future forest dynamics were simulated based on historical trends, showing a decrease in deforestation rates from 2019 to 2028. The study demonstrated that the approach can provide useful information for forest policy development.\nData:\n\nBuilding a model: Sentinel-2 and Landsat 5, 7 and 8\nModel validation: The China-Brazilian Earth Resources Satellite (CBERS) high-resolution panchromatic data\n\nModel building process:\n\nThe whole process of building Random Forest (RF) algorithm was implemented on GEE platform\n\nThe training sets - 80% for model building, and 20% for assessing the performance\n\nModel validation: a validation of the classification results was done by using high resolution (HiRes) data from CBERS\n\nDue to availability of the free HiRes data, the validation was only available for the maps of years 2010, 2015 and 2019\n\n\n\n\n\n\n\n\nWork Flow of the research (Source: Brovelli, Sun, and Yordanov (2020))\n\n\n\n\n\nResults: The RF algorithm captured the deforestation patterns with a high accuracy.\n\n\n\n\n\n\nRF Classification results - (a) Landsat 7 for 2000; (b) Landsat 5 for 2006; (c) Landsat 5 for 2010; (d) Landsat 8 for 2015; (e) Sentinel-2 for 2019 (Source: Brovelli, Sun, and Yordanov (2020))\n\n\n\n\n\n\n\n\n\nRF model’s validation results (Source: Brovelli, Sun, and Yordanov (2020))\n\n\n\n\n\nComment: The above research was utilising GEE as a main platform to build a ML model. It was very interesting to see how the GEE platform can be used apart from monitoring land cover change. This research well-demonstrated that combining satellite images and machine learning can be an effective way to monitor and forecast changes in forests. The study found a reduction in deforestation rates, but it’s important to recognise that deforestation remains an ongoing issue with severe consequences for biodiversity, climate change, and local communities. In particular, the research argues that cattle ranching and land speculation were the main driving factors for deforestation in the region. Therefore, it is vital to continue monitoring and enforcing policies that safeguard forests and encourage sustainable land use practices. The Brazilian government’s various measures to regulate illegal deforestation in the region, such as the Action Plan for Prevention and Control of Legal Amazon Deforestation (PPCDAm), are much more needed now more than ever.\nLimitation: I would like to point out an overfitting issue. If we look at the validation results, the accuracy of the model is too good to be true!! Can we be sure that training and test data are appropriately separated? The authors only mentioned that they separated the data but did not give a detailed explanation how they did it.\n\n\n5.3 Reflection\n\nThis week’s content was an introductory lecture for the GEE. The whole concept was somewhat very new and interesting for me as I have not ever heard of GEE before.\nHere are the things I noted while studying the GEE.\nThings I liked!!\n\nDatasets: are stored within GEE server so it was very convenient. Storing data always took up a lot of memory in my computer and sometimes it was hard to set up or remember a directory whenever I had to process data on R. The datasets on server saved so much space in my computer as well as the ready-made code to import the datasets was really easy.\nFast: spatial join and reducing images were much faster on GEE. With a few lines of code, I was able to get the results I wanted which would require lots of lines in other programming languages.\n\nThings I didn’t like?!\n\nJavascript: was a bit confusing. It kinds of looked similar to Python, but it was quite different in terms of defining variables.\nImage Export: was quite challenging which I spent so much time!\n\nA bit of thought…..\nI noticed that most of datasets stored within the GEE server were mostly about “environment-related datasets”. Moreover, many of the on-going research were mainly focusing on identifying change in the natural environment…\nThus, I was wondering whether there is any current research in the context of urban environment by using the GEE platform. Although the change in an urban setting might not be as distinctive as deforestation, cities are growing and urban infrastructures are always changing. This gives us enough reason to make use of GEE to better understand fast-changing cities. Therefore, in the next session, I would love to do more research about how GEE can be potentially utilised in the urban environment.\n\nReferences\n\nGoogle Earth Engine (n.d.) https://earthengine.google.com/ (Accessed: 28.02.2023)\nSpatialThoughts (2021) https://spatialthoughts.com/2021/05/13/aggregating-population-data-gee/ (Accessed: 28.02.2023)\n\n\n\n\nBrovelli, Maria Antonia, Yaru Sun, and Vasil Yordanov. 2020. “Monitoring Forest Change in the Amazon Using Multi-Temporal Remote Sensing Data and Machine Learning Classification on Google Earth Engine.” ISPRS International Journal of Geo-Information 9 (10). https://doi.org/10.3390/ijgi9100580.\n\n\nKumar, Lalit, and Onisimo Mutanga. 2018. “Google Earth Engine Applications Since Inception: Usage, Trends, and Potential.” Remote Sensing 10 (10). https://doi.org/10.3390/rs10101509."
  },
  {
    "objectID": "week_6.html",
    "href": "week_6.html",
    "title": "6  Classification I",
    "section": "",
    "text": "The classification methods can be divided into two approach - unsupervised and supervised algorithms. However, this diary will mainly focus on the supervised algorithms.\nSupervised ML follows the following process:\n- Class definition\n- Pre-processing\n- Training\n- Pixel assignment\n- Accuracy assessment\n\n\n\n\n\nSupervised Classification Process in Remote Sensing (Source: GISgeography)\n\n\n\n\n\n6.1.1 Random Forests (RF)\n\n\nOverview: RF simply means that many are better than one. We do “bootstrap” samples (bagging - only 70% of data is used), and create nodes with random number of variables and on and on. Eventually, we will make many decision trees from random number of variables. These different decision trees are called a forest. A final decision is made by aggregating the results of a collection of decision trees.\n\n\n\n\n\n\nRandom Forests Classification (Source: Feng et al, 2018)\n\n\n\n\n\nDecision process:\nThe forest is tested with the samples that were not used to create the decision trees. These samples are called “Out of Bag (OOB)” (30%). The majority of decisions made on the OOB are chosen, and the proportion fo OOB incorrectly classified are called OOB error.\nFor example, when we want to classify a pixel, if the majority of decision trees says it is an urban area, the pixel is categorised as an urban area.\nNote. OOB is different from test data as test data are never included in building decision trees.\n\n\n6.1.2 Support Vector Machine (SVM)\n\n\nOverview: SVM is a maximum margin classifier. SVM looks for a place where it can separate datasets most effectively. The benefit of SVM is that it uses structural risk minimisation which minimises errors on unseen data.\nThe distance from the diving line to the closest points is called the maximum margin. However, sometimes points from some datasets are very close to points of other datasets, which could lead to misclassification.\n\n\n\n\n\n\nIllustration of Support Vector Machine (Source: skilltohire)\n\n\n\n\n\nTerminology\n\n\n\n\n\n\n\n\nTerm\nDescription\n\n\n\n\nSoft margin\n\nAllows some wrongly classified points to get the overall best results\nUnderfitting problem as outliers are included within the margins\n\n\n\nHard margin\n\nDoes not allow any misclassification\nOverfitting issue\n\n\n\n\n\n\n\n\n\nHard and Soft margin (Source: Velocity Business Solutions)\n\n\n\n\n\nParameters of SVM: The best values for C and gamma can be searched through using grid search, which tests every possible values for the hyper-parameters\n\n\n\n\n\n\n\n\nParameter\nDescription\n\n\n\n\nC\n\nDetermines the extent of misclassification that SVM can allow\nIf ‘C’ is large, SVM has a hard margin\nIf ‘C’ is small, SVM has a soft margin\n\n\n\nKernel\n\nTransforms the data when the data cannot be linearly separated\n\n\n\nGamma\n\nDefines the decision boundary\nThe larger the ‘gamma’ is, the higher probability of overfitting is\nThe smaller the ‘gamma’ is, the more linear the decision boundary is, which might cause underfitting issues.\n\n\n\n\n\n\n\n\n\nKernel trick which projects data to a higher dimensional space (Source: Towards Data Science)\n\n\n\n\n\n\n\n\n\nIllustration of how change in gamma affects the decision boundary (Source: Analytics Vidhya)\n\n\n\n\n\nExample of the application of SVM:\nLet’s say ‘pixel 1’ has values for band 1, band 2, band 3, and so on. For reference, a pixel which has a number of band values is called Pattern vector. If there are forests, they will have many pattern vectors. If we put these into a feature space, these pattern vectors will be very close and on top of each other. This is the moment where SVM can come into play and separate them by allowing some misclassification.\n\n\n6.2 Applications\n\nSome land covers, such as wetland, are hard to classify due to unclear distinction with other surrounding land covers, massive seasonal changes in vegetation and hydrological variation. In this section, I looked into how somewhat classification-wise challenging land covers can be classified in conjunction with ML algorithms.\n\n6.2.1 Random Forest Classification of Wetland Landcovers from Multi-Sensor Data in the Arid Region of Xinjiang, China\n\n\nSummary: Tian et al. (2016) aimed to classify wetland land cover by using a random forest classification approach. The classification model was successfully developed with 19 features and achieved a satisfactory accuracy of 92.5%. The inclusion of spatial and temporal features has allowed for the accurate differentiation of wetland vegetation and water bodies from forests and crops. The study concludes that the proposed approach has significant practical values in supporting the effective management and protection of wetland resources.\nData + Processing:\n\nBy fusing the Pléiade-1B data with multi-date Landsat-8 data.\nThe former was performed based on an object-oriented approach, and the geometric and spectral features were extracted.\nFrom the latter, the normalized difference vegetation index (NDVI) data were calculated and this enabled to reflect phenological changes in vegetation. The feature datasets obtained from two sensors were optimised and used to build a RF model.\n\n\n\n\n\n\n\nFlowchart of building a RF Model (Source: Tian et al. (2016))\n\n\n\n\n\nResult:\n\nThe RF classifier obtained an overall accuracy of 93 % and the research team found out that the inclusion of the geometric shapes improved the classification accuracy of the farming lands and water bodies by 5% - 10%.\nThe challenge in classifying wetland due to similar spectral features of vegetation covers: By making use of the phenological difference and the textual information, the team reduced the classification errors and improved the overall accuracy about 10%.\nThe overall accuracy of the RF model was 10% higher than that of Support Vector Machine (SVM) and Artificial Neural Network (ANN) classifiers.\n\n\n\n\n\n\n\nImportance of Features in the RF model (Source: Tian et al. (2016))\n\n\n\n\n\nInsight:\nThe classification results bring us back to a question we had in the lecture.\n‘Does the most advanced ML classification method always achieves the best results?’\nAs shown in the results, the most advanced ML algorithms - SVM and ANN - did not achieve the best classification results. They were 10% behind the overall accuracy compared to the RF model’s result.\nThe author stated that the way that RF model builds each decision tree was significant in achieving a higher accuracy. In the RF model, each decision tree is a “specialist tree” which considers the feature domain - the data from geometric and textual features.\nFor instance, the lakes which are characterised as being large and in a circular shape with a smoother shoreline, which are rather easy to classify. However, marshes and ponds inherit heterogeneous features, and are in irregular shape, which pose difficulties in classifying them.\nTherefore, the specialist trees grown with considerations for these features in the RF model explain why the RF model achieved a higher accuracy. What we can learn from this research is that the location- and context-specific ML algorithm is required to achieve a better classification accuracy. The most advanced and state-of-the-art algorithms do not guarantee the best results.\n\n\n\n\n\n\nResearch Area (Source: Tian et al. (2016))\n\n\n\n\n\n\n\n\n\nThe Classification Results of Different ML Methods - (a) RF; (b) SVM; (c) ANN (Source: Tian et al. (2016))\n\n\n\n\n\n6.3 Reflections\n\nThe week 6’s lecture covers a number of ML algorithms that are being used in satellite imagery classification. These classification methods are employed to better distinguish one band from the other band which help classifying land cover in the image. They essentially do the same functionality in classifying data but they do it in different ways.\nAny considerations?.\n\nThe ML classifiers often make things very complicated. While state-of-the-art ML algorithms are highly accurate, they are very difficult to interpret.\nWe need to consider why we are using a specific ML algorithm to classify our data. If we could differentiate one band from the other with a simple method, is there still a necessity to use a highly developed classification method?\nWe have to think about classification itself. In reality, one pixel is not solely composed of one type of land cover types. It can co-exist with other types of land cover types. Therefore, we need to contemplate on to what extent we have to classify or ignore the values in a pixel.\n\nTakeaway message?\n\nAs a whole, the lecture enabled me to think critically about\nWhy do we use this method?\nand\nWhat are the assumptions of this specific method and are we aware of them?\nThe comprehensive understanding of the rationale behind the ML algorithm will help me choose an appropriate method based on data I am trying to analyse. I believe this will enable me to comprehend not only the accuracy of the model but to approach to my data in a holistic manner.\n\n\n\n\n\n\nClassification of Pixels (Source: Peter Fisher)\n\n\n\n\n\n\n\n\nTian, Shaohong, Xianfeng Zhang, Jie Tian, and Quan Sun. 2016. “Random Forest Classification of Wetland Landcovers from Multi-Sensor Data in the Arid Region of Xinjiang, China.” Remote Sensing 8 (11). https://doi.org/10.3390/rs8110954."
  },
  {
    "objectID": "week_7.html",
    "href": "week_7.html",
    "title": "7  Classification II",
    "section": "",
    "text": "In this section, I am going to give an overall idea of how Machine Learning (ML) classification algorithm works, explain the basic concept of sub pixel analysis and how to assess the accuracy of the models we build.\n\n7.1.1 Remote Sensing ML Classification Methods In a Nutshell\n\n\nBuilding a ML model in Remote Sensing: I drew the image below to illustrate the general idea of how ML models are built in remote sensing. The pixel values are extracted from Region of Interest (ROI), and the data are stored in a tabular format. Each row contains the values of each pixel. The output value (land cover type) that we are trying to predict is called ‘Label’, and the input data are called ‘Features’. 70% of the values are used for training a model, the rest is withheld for testing the accuracy of the model.\n\n\n\n\n\n\nML Classification Model in a Nutshell\n\n\n\n\n\nAny considerations?:\n\nFor generalizability, better use multi-year data, rather than data from one single year\nUnderstanding of spatial autocorrelation\nHard vs Soft classification\n\nA bit of thought…..\nSo far, the classification methods we covered are at a per pixel approach, which assumes that a pixel contains only one land type. However, in reality, this is hardly true as each pixel can consist of different types of land. If we are doing a research, don’t we need to set detailed criteria or reasons to say a certain pixel a specific land type when building a model and share this with people?\n\n\n7.1.2 Spectral Mixture Analysis (SMA)\n\n\nDefinition: SMA is a sub-pixel analysis technique which estimates the proportion of different land covers within a pixel based on their spectral signatures (Manolakis, Lockwood, and Cooley 2016).\n\n\n\n\n\n\nA pixel of 3 mixture components (Source: Machado and Small, 2013)\n\n\n\n\n\nAssumption: The reflectance spectrum of a pixel is a linear sum of the reflectance spectra of Endmembers (different land cover types) present within that pixel (Roberts et al. 1998).\nNote. Endmembers are spectrally-pure pixels which have homogeneous land cover, and there are typically only a few of them.\n\n\n\n\n\n\nThe V-I-S (Vegetation-Impervious surface-Soil) model of Ridd (1995) (Source: Leśko, 2013)\n\n\n\n\n\nAny considerations?:\n\nNumber of Endmembers\nPixel purity\n\nA bit of thought…..\nCan we really tell that Endmembers are representative of each land cover type? In previous lecture on signature reflectance, there was disparities in signature reflectance even between the same land cover type. For example, different tree species had different signature reflectance.\n\n\n7.1.3 Accuracy Assessment\n\n\nError matrix:\n\nProducer accuracy (Recall):\n\nHow often are a map maker’s classification of real features on the ground is correct\n\\(TP\\) / \\(TP\\) + \\(FN\\)\n\nUser accuracy (Precision):\n\nHow often the class on the map will actually be present on the ground\n\\(TP\\) / \\(TP\\) + \\(FP\\)\n\nOverall accuracy (OA):\n\nHow well a map accurately represents all the reference sites\n\\(TP\\) \\(+\\) \\(TN\\) / \\(TP + FP + FN + TN\\)\n\n\nF1:\n\nCombines both recall and precision\n\\(F1 = 2 * Precision * Recall / Precision + Recall\\)\n\n\n\n7.2 Application\n\nAll ML models need to be tested with withheld data to avoid over-fitting issues. When it comes to ML classification models in remote sensing, however, this is not enough!. There is another factor that we have to consider…\nSpatial autocorrelation!!\nTobler (1970) argued the first law of geography is that near things are more closely related than distant things. Even if we split our spatial data into training and test data, there will always be “possibilities of spatial autocorrelation”.\n\n7.2.1 Spatial dependence between training and test sets: another pitfall of classification accuracy assessment in remote sensing\n\n\nSummary: Karasiak et al. (2021) discuss how spatial autocorrelation affects remote sensing image classification and emphasizes the need to account for spatial independence between training and test sets to avoid overestimating the model’s generalization capabilities. The authors built a random forest (RF) model to classify forest stands. The research team compares the overall accuracy (OA) of six cross-validation (CV) strategies with different sample sizes - pixel and object levels, and demonstrates that spatial leave-one-out cross-validation is the most effective approach to obtaining unbiased estimates of predictive error.\nMain Findings:\n\nIgnoring spatial autocorrelation resulted in a high accuracy - overfitting- in both sample levels\nNon-spatial LOO or k - fold CV at the object level can mitigate the effect of spatial autocorrelation, when the number of sample size is not too large (50 forest stands)\n\nIf the number of sample increases (over 500 forest stands), the distance between forest stands reduces, leading to increased effect of spatial dependence between training and test datasets\n\nSpatial LOO CV is a better choice\n\nComment:\nThis paper emphasises the importance of spatial autocorrelation and spatial independence between training and test datasets in accuracy assessment. The authors show that traditional non-spatial cross-validation methods can lead to overestimating accuracy, and spatial cross-validation provides better estimates of predictive error.\nLimitation: However, the paper has limitations in terms of its generalizability to other types of remote sensing imagery and classification tasks since it only focuses on forest classification using Sentinel-2 data. Furthermore, the authors did not provide a thorough analysis of the proposed approach’s limitations and the possible trade-offs between accuracy and computational efficiency. Further research is necessary to validate the proposed approach in various contexts and to investigate its potential drawbacks and trade-offs.\n\n\n\n\n\n\nAverage OA accuracy for each CV strategies (Source: Karasiak et al, 2021)\n\n\n\n\n\n\n\n\n\nLearning curve for each CV strategies (Source: Karasiak et al, 2021)\n\n\n\n\n\n7.3 Reflection\n\nThis week’s contents helped me understand the particular characteristics of remote sensing ML models. As ML models are grounded on spatial data, spatial autocorrelation is always inherent in the data we use.\nBuilding a ML model without understanding this distinctive feature would result in a misleading classification.\nMoreover, I was pleased to see what we learnt in the previous term (Moran’s I) comes into play in solving spatial autocorrelation in ML models. This reinforced my understanding of previous lessons as well as connected it to new concepts and methodologies.\nA bit of thought…..\n\nThe object-based non-spatial CV is just an alternative of spatial CV when the sample size is not too large.\nIf we are classifying land cover types other than forest stands, would this optimal sample number be different from the forest stands? What is the optimal number of sample sizes that we are safe to use non-spatial CV to assess remote sensing ML model?\n\nIn closing this week’s diary, I would like to look into any other new ML models in remote sensing which are not covered in the lecture, and their usage in urban environments.\n\n\n\n\nKarasiak, Nicolas, Jean-François Dejoux, Claude Monteil, and David Sheeren. 2021. “Spatial Dependence Between Training and Test Sets: Another Pitfall of Classification Accuracy Assessment in Remote Sensing.” Machine Learning. https://doi.org/10.1007/s10994-021-05972-1.\n\n\nManolakis, Dimitris G., Ronald B. Lockwood, and Thomas W. Cooley. 2016. “Spectral Mixture Analysis.” In, 443493. Cambridge: Cambridge University Press. https://doi.org/10.1017/CBO9781316017876.010.\n\n\nRoberts, Dar, M. Gardner, R. Church, Susan Ustin, George Scheer, and R. O. Green. 1998. “Mapping Chaparral in the Santa Monica Mountains Using Multiple Endmember Spectral Mixture Models.” Remote Sensing of Environment 65 (September). https://doi.org/10.1016/S0034-4257(98)00037-6.\n\n\nTobler, W. R. 1970. “A Computer Movie Simulating Urban Growth in the Detroit Region.” Economic Geography 46: 234240. http://www.jstor.org/stable/143141."
  },
  {
    "objectID": "week_8.html",
    "href": "week_8.html",
    "title": "8  Urban Heat Island",
    "section": "",
    "text": "Then, I will explain how UHI-related policies at a global-, metropolitan-, and local-level vary in terms of its goal and implementation scale, and ponder how we could bridge the gap that exists between these different levels of policies.\n\n8.1 Summary\n\n\nWhat is Urban Heat Island?\n\n\nDefinition: UHI is a phenomenon where the temperature in an urban area is much warmer than its rural areas.\n\n\n\n\n\n\nDifference in Temperature due to Urban Heat Island (Source: US EPA, 2022)\n\n\n\n\n\nCauses:\n\nUrban materials which reflect less solar energy and absorb more sun’s heat - building roofs, pavements and parking lots (US EPA, 2022)\nLack of urban green spaces which do evapo-transpiration and solar blocking (US EPA, 2022)\nHeat generating human activities, such as A/C, industrial activities and vehicles, etc) (US EPA, 2022)\nUrban geometry which blocks wind corridor - tall buildings and narrow streets create urban canyons (US EPA, 2022)\n\n\n\n\n\n\n\nUrban Heat Island Effects and Factors (Source: World Bank Blogs, 2020)\n\n\n\n\n\nImpacts:\n\nSocial impacts:\n\nIncreased energy consumption, which cause a positive feedback loop\nHeat-related illness and increased mortality rate due to heat stroke\n\nEnvironmental impacts:\n\nHigher temperature during the daytime and reduced nighttime cooling effects\nIncreased green house gas emissions\n\nEconomic impacts:\n\nIncreased price of electricity\nRise in food price due to dry and hot weather\n\n\n\nDo you want to know more about UHI? Check out this amazing UHI Interpretative Dance Video made by CASA students!!\n\n8.2 Application\n\nIn this section, I am going to introduce Seoul’s urban planning policy with respect to UHI, and see how UHI mitigation activities under the metropolitan policy is in line with global policy.\n\n8.2.1 Metropolitan-level Policy\n\n\nOverview: Seoul Plan is a metropolitan-level urban planning policy in Seoul, South Korea. The plan consists of 5 focal points, and one of which is environment. Under the environment part, there are 3 targets and 11 strategies.\n\n\nPolicy relevant to UHI\n\n\nFocal Point 4: A city where life thrives/breathes\n\nTarget 1: Urban park-led ecological city\n\nStrategy 1.2: Enhancement of Urban Climate Control Capacity\n\nGuideline 1.2.2: Urban Heat Island Mitigation/Reduction\n\n\n\n\n\nUHI Reduction Activities\n\nThe Guideline 1.2.2 lists a number of UHI reduction activities which are as follows:\n\nEnabling wind corridor which brings fresh air from forests to city centre\n\n\n\n\n\n\nWind corridor forest map. (Source: Seoul Metropolitan Government)\n\n\n\n\nNote. Arrows indicate the main wind flow route. Forests play a key role in directing wind flow to city centre.\n\nImplementation of mist spray and shade canopy in the parks and bus stops\n\n\n\n\n\n\nMist spray (Source: The JoongAng, 2019)\n\n\n\n\n\n\n\n\n\nShade canopy (Source: The JoongAng, 2017)\n\n\n\n\n\nConfiguration of urban waterfronts and urban parks\n\n\n\n\n\n\nWaterfront in Seoul (Source: Seoul Metropolitan Government, 2015)\n\n\n\n\n\n\n\n\n\nUrban parks in Seoul (Source: Kookmin Ilbo, 2022)\n\n\n\n\n\nLimitation:\nSome of the mitigation activities do not necessarily cope with main causes of UHI. There should also consideration for road paving materials which enable percolation of rainwater.\nMore specific and granular-scale guidelines for implementing UHI-mitigation urban parks are needed to better locate the urban parks within the city. This is where remote sensing data could come into play in deciding the optimal location of urban green spaces. Sentinel 3 can be used to detect highly unusual temperature in cities.\nA link to Global Agenda: Seoul Plan’s UHI reduction activities could contribute to UN SDG 11. The activities listed contribute to building an environment risk resilient city. In particular, one of the UHI reduction activities under Guideline 1.2.2: configuration of urban waterfronts and urban parks is linked to\nSDG 11.7.1: Average share of the built-up area of cities that is open space for public use for all, by sex, age and persons with disabilities.\n\n\n\n\n\n\nUN SDG 11 - Global Policy (Source: United Nations)\n\n\n\n\n\n8.3 Reflection\n\nThis week’s lecture was an extended lecture of the week 4, where we learnt about policies. A few weeks ago, I did not understand the reason why there are varying levels of policies. As each country faces country-specific challenges and their contexts are quite different, I had somewhat suspicion about following global policies. However having UHI as an example enabled me to grasp the importance of creating a cohesive link between different levels of policies.\nTakeaway message?\nIt is true that global policies are ambiguous and provide unclear guidance, and each country has different context. Yet, we need to have an agreed, standardised approach as it helps us assess and monitor the actions we take, and allows for comparing outputs. As long as the local-level policies are in accordance with a higher level policies, I do believe that some adjustments can be made to better cope with the local issues.\n\nReferences\n\nUnited Nations (n.d.) SDG Indicators. Available at: https://unstats.un.org/sdgs/indicators/indicators-list/ (Accessed: 24.03.2023)\nUnited States Environmental Protection Agency (US EPA) (2022) Learn About Heat Islands. Available at: https://www.epa.gov/heatislands/learn-about-heat-islands (Accessed: 14.03.2023)"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Brovelli, Maria Antonia, Yaru Sun, and Vasil Yordanov. 2020.\n“Monitoring Forest Change in the Amazon Using Multi-Temporal\nRemote Sensing Data and Machine Learning Classification on Google Earth\nEngine.” ISPRS International Journal of Geo-Information\n9 (10). https://doi.org/10.3390/ijgi9100580.\n\n\nDaneshgar, Saba. 2015. “Remote Sensing Observations for Monitoring\nCoastal Zones, Volturno River Mouth Case Study.” PhD thesis. https://doi.org/10.13140/RG.2.1.3806.9209.\n\n\nDurgante, Flávia Machado, Niro Higuchi, Ana Almeida, and Alberto\nVicentini. 2013. “Species Spectral Signature: Discriminating\nClosely Related Plant Species in the Amazon with Near-Infrared\nLeaf-Spectroscopy.” Forest Ecology and Management 291:\n240–48. https://doi.org/https://doi.org/10.1016/j.foreco.2012.10.045.\n\n\nGupta, Pawan, Sundar A. Christopher, Jun Wang, Robert Gehrig, Yc Lee,\nand Naresh Kumar. 2006. “Satellite Remote Sensing of Particulate\nMatter and Air Quality Assessment over Global Cities.”\nAtmospheric Environment 40 (30): 5880–92. https://doi.org/https://doi.org/10.1016/j.atmosenv.2006.03.016.\n\n\nHu, Linshu, Mengjiao Qin, Feng Zhang, Zhenhong Du, and Renyi Liu. 2020.\n“RSCNN: A CNN-Based Method to Enhance Low-Light Remote-Sensing\nImages.” Remote Sensing 13 (December): 62. https://doi.org/10.3390/rs13010062.\n\n\nKarasiak, Nicolas, Jean-François Dejoux, Claude Monteil, and David\nSheeren. 2021. “Spatial Dependence Between Training and Test Sets:\nAnother Pitfall of Classification Accuracy Assessment in Remote\nSensing.” Machine Learning. https://doi.org/10.1007/s10994-021-05972-1.\n\n\nKumar, Lalit, and Onisimo Mutanga. 2018. “Google Earth Engine\nApplications Since Inception: Usage, Trends, and Potential.”\nRemote Sensing 10 (10). https://doi.org/10.3390/rs10101509.\n\n\nManolakis, Dimitris G., Ronald B. Lockwood, and Thomas W. Cooley. 2016.\n“Spectral Mixture Analysis.” In, 443493. Cambridge:\nCambridge University Press. https://doi.org/10.1017/CBO9781316017876.010.\n\n\nRoberts, Dar, M. Gardner, R. Church, Susan Ustin, George Scheer, and R.\nO. Green. 1998. “Mapping Chaparral in the Santa Monica Mountains\nUsing Multiple Endmember Spectral Mixture Models.” Remote\nSensing of Environment 65 (September). https://doi.org/10.1016/S0034-4257(98)00037-6.\n\n\nTian, Shaohong, Xianfeng Zhang, Jie Tian, and Quan Sun. 2016.\n“Random Forest Classification of Wetland Landcovers from\nMulti-Sensor Data in the Arid Region of Xinjiang, China.”\nRemote Sensing 8 (11). https://doi.org/10.3390/rs8110954.\n\n\nTobler, W. R. 1970. “A Computer Movie Simulating Urban Growth in\nthe Detroit Region.” Economic Geography 46: 234240. http://www.jstor.org/stable/143141.\n\n\nYang, Ce, Won Suk Lee, and Jeffrey G. Williamson. 2012.\n“Classification of Blueberry Fruit and Leaves Based on Spectral\nSignatures.” Biosystems Engineering 113 (4): 351–62.\nhttps://doi.org/https://doi.org/10.1016/j.biosystemseng.2012.09.009.\n\n\nZhang, Ying, Zhengqiang Li, Kaixu Bai, Yuanyuan Wei, Yisong Xie, Yuanxun\nZhang, Yang Ou, et al. 2021. “Satellite Remote Sensing of\nAtmospheric Particulate Matter Mass Concentration: Advances, Challenges,\nand Perspectives.” Fundamental Research 1 (3): 240–58.\nhttps://doi.org/https://doi.org/10.1016/j.fmre.2021.04.007."
  }
]