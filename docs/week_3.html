<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Phil’s remote sensing learning diary - 3&nbsp; Corrections</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./week_4.html" rel="next">
<link href="./week_2.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Corrections</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Phil’s remote sensing learning diary</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Hello!</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week_1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week_2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">SAR Sensor</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week_3.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Corrections</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week_4.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Policy</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week_5.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction to Google Earth Engine</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week_6.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Classification I</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week_7.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Classification II</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week_8.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Urban Heat Island</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#summary" id="toc-summary" class="nav-link active" data-scroll-target="#summary"><span class="toc-section-number">3.1</span>  3.1 Summary</a>
  <ul class="collapse">
  <li><a href="#data-distortion" id="toc-data-distortion" class="nav-link" data-scroll-target="#data-distortion"><span class="toc-section-number">3.1.1</span>  3.1.1 Data Distortion</a></li>
  <li><a href="#data-corrections" id="toc-data-corrections" class="nav-link" data-scroll-target="#data-corrections"><span class="toc-section-number">3.1.2</span>  3.1.2 Data Corrections</a></li>
  </ul></li>
  <li><a href="#application" id="toc-application" class="nav-link" data-scroll-target="#application"><span class="toc-section-number">3.2</span>  3.2 Application</a></li>
  <li><a href="#reflection" id="toc-reflection" class="nav-link" data-scroll-target="#reflection"><span class="toc-section-number">3.3</span>  3.3 Reflection</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="toc-section-number">3.4</span>  References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Corrections</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<section id="summary" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="summary"><span class="header-section-number">3.1</span> 3.1 Summary</h2>
<section id="data-distortion" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="data-distortion"><span class="header-section-number">3.1.1</span> 3.1.1 Data Distortion</h3>
<p>Remotely sensed images often require corrections to be available for analysis. The image distortions occur due to the following factors:</p>
<ul>
<li><strong>View angle</strong>: Depending on the angle of the sensor, the area of interest might look different.</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/view_angle.jpeg" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">View angle (Source: <a href="https://www.mdpi.com/2072-4292/13/24/5094">Shen et al., 2021</a>)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<ul>
<li><strong>Topography</strong>: The shape of terrain might cause some flaws in the image.</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/topography.png" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">Impact of Topography on Remote Sensing Images (Source: <a href="https://community.esri.com/t5/imagery-and-remote-sensing-blog/bg-p/imagery-and-remote-sensing-blog/page/4">Julia Lenhardt</a>)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<ul>
<li><strong>Earth rotation</strong>: Earth’s spinning motion poses another difficulty. Straight lines of an image can appear to be unnaturally curved or deformed.</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/rotation.gif" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">Effect of Earth’s motion (Source: <a href="https://www.nln.geos.ed.ac.uk/courses/english/frs/f3400/f3400005.htm">National Learning Network for Remote Sensing</a>)</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="data-corrections" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="data-corrections"><span class="header-section-number">3.1.2</span> 3.1.2 Data Corrections</h3>
<p>Geometric, Atmospheric and Orthorectification corrections can be applied to correct distorted images.</p>
<section id="geometric-correction" class="level4" data-number="3.1.2.1">
<h4 data-number="3.1.2.1" class="anchored" data-anchor-id="geometric-correction"><span class="header-section-number">3.1.2.1</span> <strong>(1)</strong> <strong>Geometric Correction</strong></h4>
<ul>
<li><p><strong>Cause</strong>: geometric error, introduced by internal and external factors (attitude and altitude change).</p></li>
<li><p><strong>Solution</strong>:</p>
<ul>
<li><p><code>Ground Control Points (GCP)</code>: “known points” in both sensed image and a reference data</p>
<ul>
<li><p><code>Backward mapping (Linear model)</code>: process of using GCP to infer the characteristics of the corresponding remote sensing data by building or refining models</p></li>
<li><p>Model verification: RMSE can be used - threshold 0.5</p></li>
</ul></li>
</ul></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/geomet.png" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">GPS points from a map and Landsat image (Source: <a href="https://geolearn.in/geometric-corrections-in-remote-sensing-images/">GeoLearn</a>)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/Geometric.png" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">Geometric Correction (Source: <a href="https://www.researchgate.net/figure/Geometric-correction-procedures_fig7_320710942">Abdul Basith</a>)</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="atmospheric-correction" class="level4" data-number="3.1.2.2">
<h4 data-number="3.1.2.2" class="anchored" data-anchor-id="atmospheric-correction"><span class="header-section-number">3.1.2.2</span> <strong>(2)</strong> <strong>Atmospheric Correction</strong></h4>
<ul>
<li>This method removes scattering and absorption effects of the atmosphere to improve the image - absorption and scattering makes an image somewhat blurry as they reduce contrast of image.</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/atmos.jpeg" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">Example of an image before and after atmospheric correction (Source: NASA)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<ul>
<li><strong>Solution</strong>: Relative and Absolute approaches</li>
</ul>
<p><strong>Relative atmospheric correction</strong></p>
<ul>
<li>Dark Object Subtraction (DOS):
<ul>
<li>Searches each band for the darkest pixel value</li>
<li>The scattering is removed by subtracting this value from every pixel in the band.</li>
</ul></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/dos.png" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">An improved image after DOS (Source: <a href="https://link.springer.com/chapter/10.1007/978-981-13-9917-6_41">Wang et al., 2019</a>)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<ul>
<li>Pseudo-Invariant Features (PIFs):
<ul>
<li>Grounded upon statistical invariance of artificial elements, which do not exhibit seasonal variation</li>
<li>The differences in PIFs reflectance between dates are assumed to be due to atmospheric conditions and are linearly related.</li>
</ul></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/pif.png" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">An improved image after employing PIFs (Source: <a href="https://doi.org/10.1016/0034-4257(88)90116-2">Schott et al., 1988</a>)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><strong>Absolute atmospheric correction</strong> converts digital brightness values into scaled surface reflectance by using atmospheric radiative transfer models.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/absolute.jpg" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">Before and after atmospheric correction using radiative transfer method (Source: <a href="https://www.sciencedirect.com/topics/earth-and-planetary-sciences/atmospheric-correction#:~:text=Atmospheric%20correction%20of%20the%20radiative,the%20atmospheric%E2%80%93surface%20remote%20sensor.">Advanced Remote Sensing</a>)</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="orthorectification-correction" class="level4" data-number="3.1.2.3">
<h4 data-number="3.1.2.3" class="anchored"><span class="header-section-number">3.1.2.3</span> <strong>(3)</strong> <strong>Orthorectification Correction</strong></h4>
<ul>
<li>This method removes distortions by making the images <u>looked right above</u> (at nadir). This correction necessitates <u>sensor geometry</u> and an <u>elevation model</u>.</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/ortho.jpg" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">An example of orthorectification correction (Source: <a href="https://www.esri.com/about/newsroom/insider/what-is-orthorectified-imagery/">Esri Insider, 2016</a>)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<h3 class="anchored" data-anchor-id="orthorectification-correction">
3.1.3 Data Join
</h3>
<p>Joining remote sensed images are coined as “<strong>Mosaicking</strong>”. Using histogram matching algorithm, similar brightness values are given to two images that are overlapped, and then the feathering is conducted.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/mosaicking.gif" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">Six raster datasets are joined into one image (Source: ArcMap)</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="image-enhancement" class="level4" data-number="3.1.2.4">
<h4 data-number="3.1.2.4" class="anchored" data-anchor-id="image-enhancement"><span class="header-section-number">3.1.2.4</span> 3.1.4 Image Enhancement</h4>
<ul>
<li><p>Materials reflect different amounts of energy in the same wavelengths. However, sensors have <u>a fixed range of Digital Number (DN)</u> values between 4 to 105.</p>
<p>The following methods could enhance the visual appearance of images by expanding this range.</p></li>
<li><p><strong>Minimum-Maximum</strong>: Utilises the <u>full range of available brightness values</u></p></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/minmax.png" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">Minimum-Maximum Linear Stretch (Source: <a href="https://www.onestopgis.com/Aerial-Photography/Digital-Imaging/Imaging-by-Scanning-Techniques/3-Contrast-Stretch.html">OneStopGIS</a>)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<ul>
<li><strong>Percentage Linear and Standard Deviation Stretch</strong>:
<ul>
<li>Similar to the Minimum-Maximum linear contrast stretch</li>
<li>It uses a specified minimum and maximum values</li>
</ul></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/percentage_stretch.png" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">Percentage Linear Contrast Stretch (Source: <a href="https://www.onestopgis.com/Aerial-Photography/Digital-Imaging/Imaging-by-Scanning-Techniques/3-Contrast-Stretch.html">OneStopGIS</a>)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<ul>
<li><strong>Piecewise Linear Contrast Stretch</strong>: Used when the distribution of a histogram in an image is bi or trimodal (<a href="http://knightlab.org/rscc/legacy/RSCC_Contrast_Enhancement.pdf">Jensen and Schill, n.d.</a>).</li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/piecewise.png" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">Piecewise Linear Contrast Stretch (Source: <a href="http://dx.doi.org/10.1109/TCE.2008.4560077">Tsai and Yeh, 2008</a>)</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="application" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="application"><span class="header-section-number">3.2</span> 3.2 Application</h2>
<p>Image enhancement techniques not only enhance visual appearance but also allow for comparison between images retrieved from different years. In this part, I did research about how else image enhancement technology can be utilised apart from improving an image quality, and a novel way of using a deep learning model to enhance the quality of image.</p>
<section id="rscnn-a-cnn-based-method-to-enhance-low-light-remote-sensing-images" class="level4" data-number="3.2.0.1">
<h4 data-number="3.2.0.1" class="anchored" data-anchor-id="rscnn-a-cnn-based-method-to-enhance-low-light-remote-sensing-images"><span class="header-section-number">3.2.0.1</span> 3.2.1 RSCNN: A CNN-Based Method to Enhance Low-Light Remote-Sensing Images</h4>
<ul>
<li><p><strong>Summary</strong>: <span class="citation" data-cites="article">Hu et al. (<a href="references.html#ref-article" role="doc-biblioref">2020</a>)</span> proposes <u>a new neural network architecture called Remote-Sensing CNN (RSCNN) for enhancing low-light remote-sensing images</u>. RSCNN uses CNNs, including LLCNN and SRCNN, and an upsampling operator to learn multi-scaled features. Due to the lack of labeled training data in remote-sensing image datasets, the study uses real natural image patches to train initially and fine-tunes with simulated remote-sensing image pairs. The study’s experiments show that RSCNN outperforms conventional techniques in terms of SSIM and PSNR and has qualitative advantages in denoising and maintaining color and texture authenticity.</p></li>
<li><p><strong>Data</strong>:</p>
<ul>
<li><p>DeepISP: It consists of 110 pairs of normal and low-light exposure images</p></li>
<li><p>UCMerced: This dataset contains 21 types of land use images</p></li>
</ul></li>
<li><p><strong>Result</strong>: The results of RSCNN are compared with traditional low-light enhancement algorithms, and the results show that RSCNN has better quantitative analysis indicators and can be applied to low-light remote-sensing image enhancement tasks.</p></li>
<li><p><strong>Comment</strong>:</p>
<p>In addition to image enhancement technologies covered in the lecture, this study demonstrates that Convolutional Neural Networks (CNN) can enhance visual appearance of image greatly. The study’s proposed RSCNN architecture is an exciting development in image enhancement technology, particularly for remote-sensing images.</p>
<p><u>The use of real natural image patches for initial training and fine-tuning with simulated remote-sensing images is a smart approach to addressing the lack of labeled training data</u>. The experiments’ qualitative and quantitative results demonstrate RSCNN’s superiority over conventional techniques, which is encouraging.</p>
<p>Overall, this research offered <u>potentials in combining two different fields of studies - CNN and remote sensing -, and suggested that adding complexity to imagery can help us more natural results with more realistic textures and vivid details</u>.</p></li>
<li><p><strong>Limitation</strong>: The proposed method is evaluated on a limited set of datasets, and the generalization of the method to other remote-sensing datasets needs to be further investigated.</p></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/ie_methods.jpg" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">Results of different image enhancement methods (Source: Hu et al., 2020)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/rscnn_result.jpg" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">SSIM and PSNR of different image enhancement methods (Source: Hu et al., 2020)</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="reflection" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="reflection"><span class="header-section-number">3.3</span> 3.3 Reflection</h2>
<p>This week’s content gave me an answer for the questions I had from the first week. <u>Numerous data correction technologies improve the quality of image collected and allow for facilitating data to be ready for analysis</u>.</p>
<p><em>Takeaway message</em></p>
<ul>
<li>As there are a variety of correction methods, it seems necessary to understand <u>what causes flaws in the remotely sensed images and how to employ an appropriate correction method to that specific datasets.</u></li>
</ul>
<p><em>A bit of thought…..</em></p>
<ul>
<li><p>Any preference in correction method?</p>
<ul>
<li>I wonder whether there is a preference in a particular correction method over other correction methods, depending on the domain of study field or industry.</li>
</ul></li>
<li><p>Object-detection model in urban environment?!</p>
<ul>
<li><p>In the context of built environment, there are many objects in cities that look similar to each other, and this might pose a difficulty in classifying them. In Data Science module, I came across a deep learning model called <strong>YOLOv5</strong>, which detects objects in remotely sensed images. The model was trained on custom datasets. Once the training is done, the model can be applied to satellite imagery of different resolutions and identify objects.</p>
<p>If we create a <strong>customised dataset which contains specific information about some types of urban infrastructure</strong>, and feed these to train a model, we might be able to build a deep learning object detection model targeted at urban environment.</p>
<p>Together with the data correction and image enhancement methods we learnt, I think the object detection model could enable us to classify some technically-challenging objects in an urban setting.</p></li>
</ul></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="img/yolo.jpg" style="width:60.0%;height:40.0%" class="figure-img"></p>
<p></p><figcaption class="figure-caption">Objects indicated by a bounding box and its probability (Source: <a href="https://oballinger.github.io/GEE_OSINT/object_detection.html">Google Earth Engine for OSINT</a>)</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="references" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="references"><span class="header-section-number">3.4</span> References</h2>
<p>Google Earth Engine for OSINT. (n.d.) ‘Object Detection in Satellite Imagery’[Online]. Available at: <a href="https://oballinger.github.io/GEE_OSINT/object_detection.html" class="uri">https://oballinger.github.io/GEE_OSINT/object_detection.html</a> (Acessed: 08.02.2023)</p>
<p>Jensen, J.H. and Schill, S.R. (n.d.) ‘Contrast Enhancement’[PDF]. Available at: <a href="http://knightlab.org/rscc/legacy/RSCC_Contrast_Enhancement.pdf" class="uri">http://knightlab.org/rscc/legacy/RSCC_Contrast_Enhancement.pdf</a> (Accessed: 08.02.2023)</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-article" class="csl-entry" role="doc-biblioentry">
Hu, Linshu, Mengjiao Qin, Feng Zhang, Zhenhong Du, and Renyi Liu. 2020. <span>“RSCNN: A CNN-Based Method to Enhance Low-Light Remote-Sensing Images.”</span> <em>Remote Sensing</em> 13 (December): 62. <a href="https://doi.org/10.3390/rs13010062">https://doi.org/10.3390/rs13010062</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./week_2.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">SAR Sensor</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./week_4.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Policy</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>